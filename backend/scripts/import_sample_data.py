#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸Šæµ·çŸ³æ²¹å¤©ç„¶æ°”äº¤æ˜“ä¸­å¿ƒä¿¡æ¯é—¨æˆ·ç³»ç»Ÿ - ç»Ÿä¸€æ•°æ®å¯¼å…¥è„šæœ¬
ä½¿ç”¨å®Œæ•´çš„51ç¯‡æ–‡ç« æ•°æ®é›†ï¼Œç¡®ä¿ä¸TagProcessorçš„æ ‡ç­¾ä¸€è‡´æ€§
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
import json
from datetime import datetime
from motor.motor_asyncio import AsyncIOMotorClient
from app.core.config import settings
from app.models.content import Content, ContentType, ContentTag
from app.models.user import User, UserRole, UserCreate, TagCategory, TagSource
from app.services.user_service import UserService
from app.utils.tag_processor import TagProcessor  # å¯¼å…¥ç»Ÿä¸€æ ‡ç­¾å¤„ç†å™¨
from passlib.context import CryptContext
from typing import List
import ast

# ä½¿ç”¨ç»Ÿä¸€çš„æ ‡ç­¾å¤„ç†å™¨é…ç½®
CONTENT_TYPE_MAP = TagProcessor.CONTENT_TYPE_MAP

# å¯†ç åŠ å¯†ä¸Šä¸‹æ–‡
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def get_content_type(basic_info_tags):
    """æ ¹æ®åŸºç¡€ä¿¡æ¯æ ‡ç­¾ç¡®å®šå†…å®¹ç±»å‹ï¼Œä½¿ç”¨TagProcessorçš„æ ‡å‡†æ˜ å°„"""
    if not basic_info_tags:
        return ContentType.NEWS  # é»˜è®¤ä¸ºè¡Œä¸šèµ„è®¯
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ ‡å‡†åŒ–çš„åŸºç¡€ä¿¡æ¯æ ‡ç­¾
    for tag in basic_info_tags:
        if tag in ["æ”¿ç­–æ³•è§„"]:
            return ContentType.POLICY
        elif tag in ["è°ƒä»·å…¬å‘Š"]:
            return ContentType.PRICE
        elif tag in ["äº¤æ˜“å…¬å‘Š"]:
            return ContentType.ANNOUNCEMENT
        elif tag in ["è¡Œä¸šèµ„è®¯", "ç ”æŠ¥åˆ†æ"]:
            return ContentType.NEWS
    
    return ContentType.NEWS  # é»˜è®¤ä¸ºè¡Œä¸šèµ„è®¯

def parse_tag_string(tag_str) -> List[str]:
    """è§£ææ ‡ç­¾å­—ç¬¦ä¸²ï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
    if not tag_str:
        return []
    
    # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨ï¼Œç›´æ¥è¿”å›
    if isinstance(tag_str, list):
        return [str(tag).strip() for tag in tag_str if tag and str(tag).strip()]
    
    # å¤„ç†å­—ç¬¦ä¸²æ ¼å¼çš„æ ‡ç­¾
    tag_str = str(tag_str).strip()
    if not tag_str or tag_str in ['[]', '[""]', "['']", 'null', 'None']:
        return []
    
    # å°è¯•è§£æJSONæ ¼å¼
    try:
        parsed = ast.literal_eval(tag_str)
        if isinstance(parsed, list):
            return [str(tag).strip() for tag in parsed if tag and str(tag).strip()]
    except:
        pass
    
    # ç®€å•åˆ†å‰²å¤„ç†
    if ',' in tag_str:
        return [tag.strip().strip("'\"") for tag in tag_str.split(',') if tag.strip()]
    
    return [tag_str.strip().strip("'\"")]

def normalize_basic_info_tags(tags):
    """æ ‡å‡†åŒ–åŸºç¡€ä¿¡æ¯æ ‡ç­¾ï¼Œä½¿ç”¨TagProcessorçš„æ ‡å‡†"""
    if not tags:
        return ["è¡Œä¸šèµ„è®¯"]  # é»˜è®¤æ ‡ç­¾
    
    normalized = []
    for tag in tags:
        tag = str(tag).strip()
        # ä½¿ç”¨TagProcessorçš„æ ‡å‡†åŸºç¡€ä¿¡æ¯æ ‡ç­¾
        if tag in TagProcessor.STANDARD_BASIC_INFO_TAGS:
            normalized.append(tag)
        else:
            # æ˜ å°„åˆ°æ ‡å‡†æ ‡ç­¾
            tag_lower = tag.lower()
            if "æ”¿ç­–" in tag or "æ³•è§„" in tag or "é€šçŸ¥" in tag or "è§„å®š" in tag:
                normalized.append("æ”¿ç­–æ³•è§„")
            elif "ä»·æ ¼" in tag or "è°ƒä»·" in tag:
                normalized.append("è°ƒä»·å…¬å‘Š")
            elif "äº¤æ˜“" in tag or "å…¬å‘Š" in tag:
                normalized.append("äº¤æ˜“å…¬å‘Š")
            elif "ç ”æŠ¥" in tag or "åˆ†æ" in tag:
                normalized.append("ç ”æŠ¥åˆ†æ")
            else:
                normalized.append("è¡Œä¸šèµ„è®¯")  # é»˜è®¤
    
    return list(set(normalized))  # å»é‡

def normalize_energy_type_tags(tags):
    """æ ‡å‡†åŒ–èƒ½æºç±»å‹æ ‡ç­¾ï¼Œç¡®ä¿ç¬¦åˆTagProcessoræ ‡å‡†"""
    if not tags:
        return []
    
    normalized = []
    standard_energy_types = TagProcessor.STANDARD_ENERGY_TYPES
    
    for tag in tags:
        tag = str(tag).strip()
        if tag in standard_energy_types:
            normalized.append(tag)
        else:
            # æ˜ å°„å¸¸è§çš„éæ ‡å‡†æ ‡ç­¾ - ä¸TagProcessor.STANDARD_ENERGY_TYPESå®Œå…¨ä¸€è‡´
            tag_lower = tag.lower()
            if "lng" in tag_lower or "æ¶²åŒ–å¤©ç„¶æ°”" in tag:
                normalized.append("æ¶²åŒ–å¤©ç„¶æ°”(LNG)")
            elif "png" in tag_lower or "ç®¡é“å¤©ç„¶æ°”" in tag:
                normalized.append("ç®¡é“å¤©ç„¶æ°”(PNG)")
            elif "lpg" in tag_lower or "æ¶²åŒ–çŸ³æ²¹æ°”" in tag:
                normalized.append("æ¶²åŒ–çŸ³æ²¹æ°”(LPG)")
            elif "å¤©ç„¶æ°”" in tag and "æ¶²åŒ–" not in tag and "ç®¡é“" not in tag:
                normalized.append("å¤©ç„¶æ°”")
            elif "åŸæ²¹" in tag:
                normalized.append("åŸæ²¹")
            elif "é‡çƒƒ" in tag:
                normalized.append("é‡çƒƒ")
            elif "ç”µåŠ›" in tag:
                normalized.append("ç”µåŠ›")
            elif "æ±½æ²¹" in tag:
                normalized.append("æ±½æ²¹")
            elif "æŸ´æ²¹" in tag and "ç”Ÿç‰©" not in tag:
                normalized.append("æŸ´æ²¹")
            elif "ç”Ÿç‰©æŸ´æ²¹" in tag:
                normalized.append("ç”Ÿç‰©æŸ´æ²¹")
            elif "æ²¥é’" in tag:
                normalized.append("æ²¥é’")
            elif "çŸ³æ²¹ç„¦" in tag:
                normalized.append("çŸ³æ²¹ç„¦")
            elif "ç…¤ç‚­" in tag or "åŠ¨åŠ›ç…¤" in tag or "ç…¤" in tag:
                normalized.append("ç…¤ç‚­")
            elif "æ ¸èƒ½" in tag or "æ ¸ç”µ" in tag:
                normalized.append("æ ¸èƒ½")
            elif "å¯å†ç”Ÿèƒ½æº" in tag or ("å¯å†ç”Ÿ" in tag and "èƒ½æº" in tag):
                normalized.append("å¯å†ç”Ÿèƒ½æº")
            elif "ç”Ÿç‰©è´¨èƒ½" in tag or ("ç”Ÿç‰©è´¨" in tag and ("èƒ½" in tag or "å‘ç”µ" in tag)):
                normalized.append("ç”Ÿç‰©è´¨èƒ½")
            elif "æ°¢èƒ½" in tag or "æ°¢ç‡ƒæ–™" in tag or "æ°¢æ°”" in tag:
                normalized.append("æ°¢èƒ½")
            # å¦‚æœæ— æ³•æ˜ å°„ï¼Œä¿ç•™åŸæ ‡ç­¾ï¼ˆä½†ä¼šåœ¨åç»­éªŒè¯ä¸­æ ‡è®°ï¼‰
            else:
                normalized.append(tag)
    
    return list(set(normalized))  # å»é‡

async def import_articles(use_simplified=True):
    """å¯¼å…¥æ–‡ç« æ•°æ®åˆ°æ•°æ®åº“"""
    try:
        # ä½¿ç”¨æ¸…ç†åçš„ç»Ÿä¸€æ•°æ®é›†
        data_file = "scripts/èƒ½æºä¿¡æ¯æœåŠ¡ç³»ç»Ÿ_æ¸…ç†é‡å¤å­—æ®µ_51ç¯‡.json"
        print(f"ğŸ“– å¼€å§‹å¯¼å…¥æ•°æ®: {data_file}")
        
        with open(data_file, 'r', encoding='utf-8') as f:
            articles_data = json.load(f)
        
        if not articles_data:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ–‡ç« æ•°æ®")
            return
        
        print(f"ğŸ“Š å‡†å¤‡å¯¼å…¥ {len(articles_data)} ç¯‡æ–‡ç« ")
        
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        client = AsyncIOMotorClient("mongodb://localhost:27017")
        db = client["energy_info"]
        content_collection = db["content"]
        
        # æ¸…ç©ºç°æœ‰æ•°æ®
        await content_collection.delete_many({})
        print("ğŸ—‘ï¸  å·²æ¸…ç©ºç°æœ‰æ–‡ç« æ•°æ®")
        
        # ç»Ÿè®¡ä¿¡æ¯
        success_count = 0
        error_count = 0
        basic_info_counts = {}
        energy_type_counts = {}
        
        # é€ç¯‡å¯¼å…¥æ–‡ç« 
        for i, article_data in enumerate(articles_data, 1):
            try:
                # åŸºç¡€å­—æ®µå¤„ç†
                title = article_data.get('æ ‡é¢˜', f'æœªçŸ¥æ ‡é¢˜_{i}')
                content = article_data.get('æ–‡ç« å†…å®¹', '')
                publish_date_str = article_data.get('å‘å¸ƒæ—¥æœŸ') or article_data.get('å‘å¸ƒæ—¶é—´', '2025-01-01')
                source = article_data.get('æ¥æºæœºæ„', 'æœªçŸ¥æ¥æº')
                link = article_data.get('é“¾æ¥', '')
                
                # ğŸ”¥ æ­£ç¡®å¤„ç†å‘å¸ƒæ—¶é—´ï¼šå°†å‘å¸ƒæ—¥æœŸè½¬æ¢ä¸ºdatetimeå¯¹è±¡
                publish_time = None
                publish_date = None
                
                try:
                    if publish_date_str:
                        # å¦‚æœæ˜¯YYYY-MM-DDæ ¼å¼ï¼Œè¡¥å…¨æ—¶åˆ†ç§’ä¸º00:00:00
                        if len(publish_date_str) == 10 and '-' in publish_date_str:
                            publish_time = datetime.strptime(publish_date_str + " 00:00:00", "%Y-%m-%d %H:%M:%S")
                            publish_date = publish_date_str
                        else:
                            # å°è¯•å…¶ä»–æ ¼å¼
                            publish_time = datetime.fromisoformat(publish_date_str.replace('Z', '+00:00'))
                            publish_date = publish_time.strftime('%Y-%m-%d')
                    else:
                        # å¦‚æœæ²¡æœ‰å‘å¸ƒæ—¶é—´ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                        publish_time = datetime.now()
                        publish_date = publish_time.strftime('%Y-%m-%d')
                except Exception as e:
                    print(f"âš ï¸ è§£ææ—¶é—´å¤±è´¥: {title[:30]} - {publish_date_str} - {str(e)}")
                    publish_time = datetime.now()
                    publish_date = publish_time.strftime('%Y-%m-%d')
                
                # ğŸ”¥ ç›´æ¥ä½¿ç”¨æ¸…ç†åçš„basic_info_tagså­—æ®µ
                basic_info_tags_raw = article_data.get('basic_info_tags', [])
                
                # ç¡®ä¿basic_info_tagsæ˜¯æ•°ç»„æ ¼å¼
                if isinstance(basic_info_tags_raw, str):
                    basic_info_tags = parse_tag_string(basic_info_tags_raw)
                elif isinstance(basic_info_tags_raw, list):
                    basic_info_tags = basic_info_tags_raw
                else:
                    basic_info_tags = []
                
                # æ ‡å‡†åŒ–åŸºç¡€ä¿¡æ¯æ ‡ç­¾
                basic_info_tags = normalize_basic_info_tags(basic_info_tags)
                
                # ğŸ”¥ åŸºäºåŸºç¡€ä¿¡æ¯æ ‡ç­¾ç¡®å®šå†…å®¹ç±»å‹
                content_type = get_content_type(basic_info_tags)
                
                # å¤„ç†å…¶ä»–æ ‡ç­¾å­—æ®µ
                energy_type_tags_raw = article_data.get('èƒ½æºå“ç§æ ‡ç­¾', [])
                if isinstance(energy_type_tags_raw, str):
                    energy_type_tags = parse_tag_string(energy_type_tags_raw)
                else:
                    energy_type_tags = energy_type_tags_raw if isinstance(energy_type_tags_raw, list) else []
                
                energy_type_tags = normalize_energy_type_tags(energy_type_tags)
                
                # åœ°åŸŸæ ‡ç­¾å¤„ç†
                region_tags = []
                if article_data.get('è§„èŒƒåŒ–åœ°åŸŸæ ‡ç­¾'):
                    region_tags.extend(article_data['è§„èŒƒåŒ–åœ°åŸŸæ ‡ç­¾'])
                
                # ä¸šåŠ¡é¢†åŸŸæ ‡ç­¾
                business_field_tags_raw = article_data.get('ä¸šåŠ¡é¢†åŸŸ/ä¸»é¢˜æ ‡ç­¾', [])
                business_field_tags = parse_tag_string(business_field_tags_raw) if isinstance(business_field_tags_raw, str) else business_field_tags_raw
                
                # å—ç›Šä¸»ä½“æ ‡ç­¾
                beneficiary_tags_raw = article_data.get('å—ç›Šä¸»ä½“æ ‡ç­¾', [])
                beneficiary_tags = parse_tag_string(beneficiary_tags_raw) if isinstance(beneficiary_tags_raw, str) else beneficiary_tags_raw
                
                # æ”¿ç­–æªæ–½æ ‡ç­¾
                policy_measure_tags_raw = article_data.get('å…³é”®æªæ–½/æ”¿ç­–æ ‡ç­¾', [])
                policy_measure_tags = parse_tag_string(policy_measure_tags_raw) if isinstance(policy_measure_tags_raw, str) else policy_measure_tags_raw
                
                # é‡è¦æ€§æ ‡ç­¾
                importance_tags_raw = article_data.get('é‡è¦æ€§/å½±å“åŠ›æ ‡ç­¾', [])
                importance_tags = parse_tag_string(importance_tags_raw) if isinstance(importance_tags_raw, str) else importance_tags_raw
                
                # ğŸ”¥ åˆ›å»ºæ–‡ç« æ–‡æ¡£ï¼ŒåŒæ—¶åŒ…å«publish_dateå’Œpublish_timeå­—æ®µ
                article_doc = {
                    "title": title,
                    "content": content,
                    "publish_date": publish_date,  # å­—ç¬¦ä¸²æ ¼å¼çš„æ—¥æœŸ
                    "publish_time": publish_time,  # datetimeå¯¹è±¡
                    "source": source,
                    "link": link,
                    "type": content_type,  # ğŸ”¥ åŸºäºbasic_info_tagsç”Ÿæˆ
                    "basic_info_tags": basic_info_tags,
                    "region_tags": region_tags,
                    "energy_type_tags": energy_type_tags,
                    "business_field_tags": business_field_tags if isinstance(business_field_tags, list) else [],
                    "beneficiary_tags": beneficiary_tags if isinstance(beneficiary_tags, list) else [],
                    "policy_measure_tags": policy_measure_tags if isinstance(policy_measure_tags, list) else [],
                    "importance_tags": importance_tags if isinstance(importance_tags, list) else [],
                    "created_at": datetime.now(),
                    "updated_at": datetime.now()
                }
                
                # æ’å…¥æ•°æ®åº“
                result = await content_collection.insert_one(article_doc)
                
                if result.inserted_id:
                    success_count += 1
                    
                    # ç»Ÿè®¡åŸºç¡€ä¿¡æ¯æ ‡ç­¾
                    for tag in basic_info_tags:
                        basic_info_counts[tag] = basic_info_counts.get(tag, 0) + 1
                    
                    # ç»Ÿè®¡èƒ½æºç±»å‹æ ‡ç­¾
                    for tag in energy_type_tags:
                        energy_type_counts[tag] = energy_type_counts.get(tag, 0) + 1
                    
                    if i <= 5:
                        print(f"âœ… æ–‡ç«  {i}: {title[:30]}... -> {publish_date}")
                else:
                    error_count += 1
                    print(f"âŒ æ–‡ç«  {i} æ’å…¥å¤±è´¥")
                    
            except Exception as e:
                error_count += 1
                print(f"âŒ å¤„ç†æ–‡ç«  {i} æ—¶å‡ºé”™: {str(e)}")
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š å¯¼å…¥å®Œæˆç»Ÿè®¡ï¼š")
        print(f"æˆåŠŸå¯¼å…¥: {success_count} ç¯‡")
        print(f"å¯¼å…¥å¤±è´¥: {error_count} ç¯‡")
        print(f"æ€»è®¡: {len(articles_data)} ç¯‡")
        
        # ğŸ“‹ åŸºç¡€ä¿¡æ¯æ ‡ç­¾åˆ†å¸ƒï¼ˆéªŒè¯æ¸…ç†æ•ˆæœï¼‰
        print(f"\nğŸ“Š åŸºç¡€ä¿¡æ¯æ ‡ç­¾åˆ†å¸ƒï¼š")
        for tag, count in sorted(basic_info_counts.items(), key=lambda x: x[1], reverse=True):
            print(f"  {tag}: {count} ç¯‡")
        
        print(f"   åŸºç¡€ä¿¡æ¯æ ‡ç­¾å·²æ ‡å‡†åŒ–: {len(basic_info_counts)} ç§")
        
        # ğŸ·ï¸ èƒ½æºç±»å‹æ ‡ç­¾åˆ†å¸ƒ
        print(f"\nğŸ·ï¸ èƒ½æºç±»å‹æ ‡ç­¾åˆ†å¸ƒï¼ˆå‰10ï¼‰ï¼š")
        sorted_energy = sorted(energy_type_counts.items(), key=lambda x: x[1], reverse=True)
        for tag, count in sorted_energy[:10]:
            print(f"  {tag}: {count} ç¯‡")
        
        # ğŸ”¥ å…³é—­æ•°æ®åº“è¿æ¥
        if client:
            client.close()
        print(f"\nâœ… æ•°æ®å¯¼å…¥å®Œæˆï¼ä½¿ç”¨æ¸…ç†åçš„æ ‡å‡†åŒ–æ•°æ®ï¼Œpublish_timeå­—æ®µå·²æ­£ç¡®è®¾ç½®")
        
    except Exception as e:
        print(f"âŒ å¯¼å…¥è¿‡ç¨‹å‡ºé”™: {str(e)}")
        raise

async def create_sample_users():
    """åˆ›å»ºç¤ºä¾‹ç”¨æˆ·æ•°æ®"""
    client = None
    try:
        # åˆå§‹åŒ–MongoDBå®¢æˆ·ç«¯
        client = AsyncIOMotorClient(settings.MONGODB_URL)
        db = client[settings.DATABASE_NAME]
        users_collection = db.users
        user_tags_collection = db.user_tags
        
        # æ¸…ç©ºç°æœ‰æ•°æ®
        await users_collection.delete_many({})
        await user_tags_collection.delete_many({})
        print("Cleared existing user data")
        
        # åˆ›å»ºUserServiceå®ä¾‹
        user_service = UserService(db)
        
        # ğŸ“Š æ ¹æ®èƒ½æºæ ‡ç­¾è¦†ç›–ç‡ä¼˜åŒ–çš„æ¼”ç¤ºç”¨æˆ·ï¼ˆæ¯ç”¨æˆ·1ä¸ªèƒ½æºæ ‡ç­¾ï¼‰
        # è¦†ç›–ç‡ç»Ÿè®¡ï¼šå¤©ç„¶æ°”42.2%ï¼ŒåŸæ²¹42.2%ï¼ŒLNG24.4%ï¼ŒPNG22.2%ï¼Œç”µåŠ›8.9%
        demo_users = [
            {
                "email": "zhang@shanghai.com",
                "username": "å¼ å·¥ç¨‹å¸ˆ",
                "password": "demo123",
                "register_city": "ä¸Šæµ·",
                "energy_types": ["æ¶²åŒ–çŸ³æ²¹æ°”(LPG)"],  # è¦†ç›–ç‡æœ€é«˜ï¼š42.2% (19ç¯‡)
                "user_id": "user001",
                "description": "çŸ³æ²¹ä¸å¤©ç„¶æ°”å¸‚åœºåˆ†æå¸ˆ - å…³æ³¨è¡Œä¸šä»·æ ¼ä¸æ”¿ç­–"
            },
            {
                "email": "li@beijing.com", 
                "username": "æç»ç†",
                "password": "demo123",
                "register_city": "åŒ—äº¬",
                "energy_types": ["é‡çƒƒ"],  # è¦†ç›–ç‡æœ€é«˜ï¼š42.2% (19ç¯‡)
                "user_id": "user002",
                "description": "çŸ³æ²¹è´¸æ˜“ä¸“å®¶ - åŸæ²¹è¿›å£ä¸ä»·æ ¼åˆ†æ"
            },
            {
                "email": "wang@shenzhen.com",
                "username": "ç‹ä¸»ä»»", 
                "password": "demo123",
                "register_city": "æ·±åœ³",
                "energy_types": ["æ¶²åŒ–å¤©ç„¶æ°”(LNG)"],  # ç¬¬ä¸‰é«˜ï¼š24.4% (11ç¯‡)
                "user_id": "user003",
                "description": "LNGé¡¹ç›®ç»ç† - æ¶²åŒ–å¤©ç„¶æ°”æ¥æ”¶ç«™è¿è¥"
            },
            {
                "email": "chen@guangzhou.com",
                "username": "é™ˆæ€»ç›‘",
                "password": "demo123", 
                "register_city": "å¹¿å·",
                "energy_types": ["ç®¡é“å¤©ç„¶æ°”(PNG)"],  # ç¬¬å››é«˜ï¼š22.2% (10ç¯‡)
                "user_id": "user004",
                "description": "ç®¡é“å¤©ç„¶æ°”è¿è¥ä¸“å®¶ - å¤©ç„¶æ°”ç®¡ç½‘å»ºè®¾"
            },
            {
                "email": "liu@chengdu.com",
                "username": "åˆ˜ç ”ç©¶å‘˜",
                "password": "demo123",
                "register_city": "æˆéƒ½",
                "energy_types": ["ç”µåŠ›"],  # ç¬¬äº”é«˜ï¼š8.9% (4ç¯‡)
                "user_id": "user005", 
                "description": "ç”µåŠ›ç³»ç»Ÿç ”ç©¶å‘˜ - å¯å†ç”Ÿèƒ½æºå‘ç”µ"
            }
        ]
        
        created_count = 0
        for user_data in demo_users:
            try:
                # åˆ›å»ºç”¨æˆ·å¯¹è±¡
                user_create = UserCreate(
                    email=user_data["email"],
                    username=user_data["username"],
                    password=user_data["password"],
                    register_city=user_data["register_city"]
                )
                
                # åˆ›å»ºç”¨æˆ·ï¼ˆåŒ…å«ä¸‰å±‚åœ°åŒºæ ‡ç­¾ï¼‰
                user = await user_service.create_user(
                    user_create, 
                    energy_types=user_data["energy_types"]
                )
                
                # æ‰‹åŠ¨è®¾ç½®ç”¨æˆ·IDä¸ºé¢„è®¾å€¼ï¼Œç¡®ä¿ä¸å‰ç«¯ä¸€è‡´
                await users_collection.update_one(
                    {"id": user.id},
                    {"$set": {"demo_user_id": user_data["user_id"], "description": user_data["description"]}}
                )
                
                # æ›´æ–°ç”¨æˆ·æ ‡ç­¾é›†åˆä¸­çš„ç”¨æˆ·IDå¼•ç”¨
                await user_tags_collection.update_one(
                    {"user_id": user.id},
                    {"$set": {"demo_user_id": user_data["user_id"]}}
                )
                
                created_count += 1
                print(f"Created demo user: {user.username} ({user.email}) - {user_data['register_city']}")
                print(f"  Demo ID: {user_data['user_id']}")
                print(f"  Description: {user_data['description']}")
                
                # æ˜¾ç¤ºç”Ÿæˆçš„æ ‡ç­¾ä¿¡æ¯
                user_tags = await user_service.get_user_tags(user.id)
                if user_tags:
                    print(f"  Generated tags:")
                    for tag in user_tags.tags:
                        print(f"    - {tag.category}: {tag.name} (æƒé‡: {tag.weight}, æ¥æº: {tag.source})")
                print("")
                
            except Exception as e:
                print(f"Error creating user {user_data['email']}: {str(e)}")
        
        print(f"Total demo users created: {created_count}")
        
    except Exception as e:
        print(f"Error creating sample users: {str(e)}")
    finally:
        if client:
            client.close()

async def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    use_simplified = True  # é»˜è®¤ä½¿ç”¨ç®€åŒ–æ•°æ®
    if len(sys.argv) > 1:
        if sys.argv[1] == '--full' or sys.argv[1] == '-f':
            use_simplified = False
        elif sys.argv[1] == '--use-simplified-data' or sys.argv[1] == '--simplified':
            use_simplified = True
        elif sys.argv[1] == '--help' or sys.argv[1] == '-h':
            print("ä½¿ç”¨æ–¹æ³•:")
            print("  python import_sample_data.py                    # ä½¿ç”¨ç®€åŒ–æµ‹è¯•æ•°æ®ï¼ˆæ¯ç¯‡3-5æ ‡ç­¾ï¼‰")
            print("  python import_sample_data.py --simplified       # ä½¿ç”¨ç®€åŒ–æµ‹è¯•æ•°æ®ï¼ˆåŒä¸Šï¼‰")
            print("  python import_sample_data.py --use-simplified-data # ä½¿ç”¨ç®€åŒ–æµ‹è¯•æ•°æ®ï¼ˆåŒä¸Šï¼‰")
            print("  python import_sample_data.py -f                 # ä½¿ç”¨å®Œæ•´åŸå§‹æ•°æ®ï¼ˆæ¯ç¯‡15+æ ‡ç­¾ï¼‰")
            print("  python import_sample_data.py --full             # åŒä¸Š")
            return
    
    print(f"ğŸ“Š å¼€å§‹æ•°æ®å¯¼å…¥... ä½¿ç”¨{'ç®€åŒ–' if use_simplified else 'å®Œæ•´'}æ•°æ®")
    print("=" * 60)
    
    print("Starting data import...")
    
    # å¯¼å…¥æ–‡ç« æ•°æ®
    print("\n1. Importing articles...")
    await import_articles(use_simplified=use_simplified)
    
    # åˆ›å»ºç¤ºä¾‹ç”¨æˆ·
    print("\n2. Creating sample users...")
    await create_sample_users()
    
    print("\nData import completed!")
    
    if use_simplified:
        print("\nğŸ¯ å·²å¯¼å…¥ç®€åŒ–æµ‹è¯•æ•°æ®ï¼")
        print("ğŸ’¡ æµ‹è¯•å»ºè®®ï¼š")
        print("   1. å‰ç«¯æ ‡ç­¾ç®¡ç†é¡µé¢ä¿®æ”¹ç”¨æˆ·æ ‡ç­¾")
        print("   2. è§‚å¯Ÿé¦–é¡µæ¨èå†…å®¹çš„å˜åŒ–")
        print("   3. æ ‡ç­¾å°‘æ›´å®¹æ˜“çœ‹å‡ºæ¨èå·®å¼‚")
    else:
        print("\nğŸ“‹ å·²å¯¼å…¥å®Œæ•´åŸå§‹æ•°æ®")
        print("âš ï¸  æ³¨æ„ï¼šæ¯ç¯‡æ–‡ç« æ ‡ç­¾è¾ƒå¤šï¼Œå¯èƒ½ä¸åˆ©äºæµ‹è¯•æ¨èæ•ˆæœ")

if __name__ == "__main__":
    asyncio.run(main()) 