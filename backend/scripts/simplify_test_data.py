import json
import random
import os
from typing import List, Dict, Any
from china_regions import find_regions_in_text, classify_region_type

def parse_tag_string(tag_str: str) -> List[str]:
    """è§£æžæ ‡ç­¾å­—ç¬¦ä¸²ï¼Œå¤„ç†å„ç§æ ¼å¼"""
    if not tag_str:
        return []
    
    # ç§»é™¤å¤–å±‚çš„å•å¼•å·å’Œæ–¹æ‹¬å·
    tag_str = tag_str.strip()
    if tag_str.startswith("[") and tag_str.endswith("]"):
        # å¤„ç† "['tag1', 'tag2']" æ ¼å¼
        try:
            import ast
            return ast.literal_eval(tag_str)
        except:
            # å¦‚æžœè§£æžå¤±è´¥ï¼Œæ‰‹åŠ¨å¤„ç†
            content = tag_str[1:-1]  # ç§»é™¤ []
            if content:
                # å¤„ç†å¼•å·
                if content.startswith("'") and content.endswith("'"):
                    content = content[1:-1]
                tags = [tag.strip().strip("'\"") for tag in content.split("',")]
                return [tag for tag in tags if tag]
    
    return []

def simplify_article_tags(article: Dict[str, Any]) -> Dict[str, Any]:
    """ç®€åŒ–å•ç¯‡æ–‡ç« çš„æ ‡ç­¾ï¼Œé‡ç‚¹ä¿ç•™åœ°åŸŸå’Œèƒ½æºç±»åž‹ï¼ŒæŽ§åˆ¶æ€»æ•°åœ¨3-5ä¸ª"""
    
    # ðŸ”‹ å¤„ç†èƒ½æºç±»åž‹æ ‡ç­¾ - ä¼˜å…ˆä½¿ç”¨è§„èŒƒåŒ–åŽçš„æ•°æ®
    if "èƒ½æºå“ç§æ ‡ç­¾" in article and article["èƒ½æºå“ç§æ ‡ç­¾"]:
        # ä½¿ç”¨è§„èŒƒåŒ–åŽçš„èƒ½æºç±»åž‹
        energy_type_tags = article["èƒ½æºå“ç§æ ‡ç­¾"][:2]  # æœ€å¤šä¿ç•™2ä¸ªèƒ½æºç±»åž‹
        print(f"   ä½¿ç”¨è§„èŒƒåŒ–èƒ½æºç±»åž‹: {energy_type_tags}")
    else:
        # å›žé€€åˆ°åŽŸå§‹æ ‡ç­¾è§£æž
        original_tags = parse_tag_string(article.get("åœ°åŸŸæ ‡ç­¾", ""))
        energy_type_tags = []
        for tag in original_tags:
            if any(keyword in tag for keyword in ["å¤©ç„¶æ°”", "åŽŸæ²¹", "æ±½æ²¹", "æŸ´æ²¹", "ç”µåŠ›", "ç…¤ç‚­", "LNG", "LPG"]):
                energy_type_tags.append(tag)
        energy_type_tags = energy_type_tags[:2]  # æœ€å¤š2ä¸ª
    
    # ðŸ›ï¸ ä½¿ç”¨å®Œæ•´åœ°åŸŸæ•°æ®è¿›è¡Œåœ°åŸŸæ ‡ç­¾è¯†åˆ«
    article_text = article.get("æ ‡é¢˜", "") + " " + article.get("æ–‡ç« å†…å®¹", "")
    
    # ðŸŽ¯ ä¼˜å…ˆä½¿ç”¨è§„èŒƒåŒ–åŽçš„åœ°åŸŸæ ‡ç­¾
    if "è§„èŒƒåŒ–åœ°åŸŸæ ‡ç­¾" in article and article["è§„èŒƒåŒ–åœ°åŸŸæ ‡ç­¾"]:
        # ä½¿ç”¨è§„èŒƒåŒ–åŽçš„åœ°åŸŸæ ‡ç­¾
        selected_regions = article["è§„èŒƒåŒ–åœ°åŸŸæ ‡ç­¾"][:2]  # æœ€å¤š2ä¸ª
        print(f"   ä½¿ç”¨è§„èŒƒåŒ–åœ°åŸŸæ ‡ç­¾: {selected_regions}")
    else:
        # å›žé€€åˆ°å®žæ—¶åœ°åŸŸè¯†åˆ«
        found_regions = find_regions_in_text(article_text)
        
        # è§£æžåŽŸå§‹åœ°åŸŸæ ‡ç­¾ï¼ˆä½œä¸ºè¡¥å……ï¼‰
        original_region_tags = parse_tag_string(article.get("åœ°åŸŸæ ‡ç­¾", ""))
        
        # åˆå¹¶å‘çŽ°çš„åœ°åŸŸå’ŒåŽŸå§‹æ ‡ç­¾
        all_region_candidates = []
        
        # æ·»åŠ ä»Žæ–‡æœ¬ä¸­å‘çŽ°çš„åœ°åŸŸ
        for region_info in found_regions:
            all_region_candidates.append({
                "name": region_info["name"],
                "weight": region_info["weight"],
                "level": region_info["level"],
                "type": region_info["type"],
                "source": "text_analysis"
            })
        
        # æ·»åŠ åŽŸå§‹æ ‡ç­¾ä¸­çš„åœ°åŸŸï¼ˆç»™äºˆè¾ƒä½Žæƒé‡ï¼‰
        for tag in original_region_tags:
            region_info = classify_region_type(tag)
            if region_info["type"] != "unknown":
                # é¿å…é‡å¤
                if not any(candidate["name"] == tag for candidate in all_region_candidates):
                    all_region_candidates.append({
                        "name": tag,
                        "weight": region_info["weight"] * 0.8,  # åŽŸå§‹æ ‡ç­¾æƒé‡é™ä½Ž
                        "level": region_info["level"],
                        "type": region_info["type"],
                        "source": "original_tags"
                    })
        
        # æŒ‰æƒé‡å’Œçº§åˆ«æŽ’åºï¼Œé€‰æ‹©æœ€ä½³åœ°åŸŸæ ‡ç­¾
        all_region_candidates.sort(key=lambda x: (x["level"], x["weight"]), reverse=True)
        
        # ðŸŽ¯ åœ°åŸŸæ ‡ç­¾é€‰æ‹©ç­–ç•¥
        selected_regions = []
        
        # 1. ä¼˜å…ˆé€‰æ‹©ç›´è¾–å¸‚å’Œçœä¼šåŸŽå¸‚ï¼ˆlevel=4, weight>=2.5ï¼‰
        high_level_regions = [r for r in all_region_candidates if r["level"] == 4 and r["weight"] >= 2.5]
        if high_level_regions:
            selected_regions.append(high_level_regions[0]["name"])
        
        # 2. å¦‚æžœæ²¡æœ‰é«˜çº§åˆ«åŸŽå¸‚ï¼Œé€‰æ‹©çœä»½çº§åˆ«çš„åœ°åŸŸ
        if not selected_regions:
            province_regions = [r for r in all_region_candidates if r["level"] == 3]
            if province_regions:
                selected_regions.append(province_regions[0]["name"])
        
        # 3. æœ€å¤šå†æ·»åŠ ä¸€ä¸ªé‡è¦åœ°åŸŸï¼ˆé¿å…è¿‡å¤šåœ°åŸŸæ ‡ç­¾ï¼‰
        remaining_regions = [r for r in all_region_candidates 
                            if r["name"] not in selected_regions and r["weight"] >= 1.5]
        if remaining_regions and len(selected_regions) < 2:
            selected_regions.append(remaining_regions[0]["name"])
        
        print(f"   å®žæ—¶è¯†åˆ«åœ°åŸŸæ ‡ç­¾: {selected_regions}")
    
    # ðŸ­ å¤„ç†å…¶ä»–ç±»åž‹æ ‡ç­¾
    original_tags = parse_tag_string(article.get("ä¸šåŠ¡é¢†åŸŸ/ä¸»é¢˜æ ‡ç­¾", ""))
    business_tags = []
    importance_tags = []
    
    for tag in original_tags:
        if any(keyword in tag for keyword in ["å‘ç”µ", "ç‚¼åŒ–", "å‚¨è¿", "é”€å”®", "è´¸æ˜“", "è¿è¾“", "é…é€", "é›¶å”®"]):
            business_tags.append(tag)
        elif any(keyword in tag for keyword in ["é‡å¤§", "é‡è¦", "å…³é”®", "æ ¸å¿ƒ", "æ”¿ç­–", "æ³•è§„"]):
            importance_tags.append(tag)
    
    # âš–ï¸ æ ‡ç­¾æ•°é‡å¹³è¡¡ç­–ç•¥ï¼ˆç›®æ ‡ï¼š3-5ä¸ªæ€»æ ‡ç­¾ï¼‰
    selected_tags = {
        "region_tags": selected_regions[:2],  # æœ€å¤š2ä¸ªåœ°åŸŸæ ‡ç­¾
        "energy_type_tags": energy_type_tags,
        "business_field_tags": business_tags[:1],  # æœ€å¤š1ä¸ªä¸šåŠ¡æ ‡ç­¾
        "basic_info_tags": [article.get("æ–‡æ¡£ç±»åž‹", "")] if article.get("æ–‡æ¡£ç±»åž‹") else [],
        "importance_tags": []
    }
    
    # è®¡ç®—å½“å‰æ ‡ç­¾æ€»æ•°
    current_total = (
        len(selected_tags["region_tags"]) +
        len(selected_tags["energy_type_tags"]) +
        len(selected_tags["business_field_tags"]) +
        len(selected_tags["basic_info_tags"])
    )
    
    # å¦‚æžœæ€»æ•°å°‘äºŽ3ä¸ªï¼Œæ·»åŠ é‡è¦æ€§æ ‡ç­¾
    if current_total < 3 and importance_tags:
        available_slots = min(3 - current_total, len(importance_tags))
        selected_tags["importance_tags"] = importance_tags[:available_slots]
    
    # ðŸ“Š è¾“å‡ºåœ°åŸŸè¯†åˆ«è¯¦æƒ…
    found_regions = []  # ç¡®ä¿å˜é‡æ€»æ˜¯è¢«å®šä¹‰
    if "è§„èŒƒåŒ–åœ°åŸŸæ ‡ç­¾" in article and article["è§„èŒƒåŒ–åœ°åŸŸæ ‡ç­¾"]:
        # ä½¿ç”¨è§„èŒƒåŒ–åŽçš„åœ°åŸŸæ ‡ç­¾æ—¶ï¼Œfound_regionsä¸ºç©ºï¼ˆå› ä¸ºæ²¡æœ‰å®žæ—¶è¯†åˆ«ï¼‰
        pass
    else:
        # åªæœ‰åœ¨å®žæ—¶è¯†åˆ«æ—¶æ‰æœ‰found_regionsæ•°æ®
        found_regions = find_regions_in_text(article_text)
    
    if found_regions:
        print(f"   å‘çŽ°åœ°åŸŸæ ‡ç­¾: {[r['name'] for r in found_regions[:3]]}")
    
    print(f"   æœ€ç»ˆé€‰æ‹©åœ°åŸŸ: {selected_regions}")
    
    # åˆ›å»ºç®€åŒ–çš„æ–‡ç« æ•°æ®
    simplified_article = article.copy()
    simplified_article.update(selected_tags)
    
    return simplified_article

def create_simplified_data():
    """åˆ›å»ºç®€åŒ–çš„æµ‹è¯•æ•°æ®"""
    
    # ä¼˜å…ˆä½¿ç”¨è§„èŒƒåŒ–åŽçš„æ•°æ®
    normalized_file = os.path.join(os.path.dirname(__file__), "ä¿¡æ¯å‘å¸ƒæ–‡ç« ä¸Žæ ‡ç­¾_è§„èŒƒåŒ–.json")
    original_file = os.path.join(os.path.dirname(__file__), "ä¿¡æ¯å‘å¸ƒæ–‡ç« ä¸Žæ ‡ç­¾.json")
    
    if os.path.exists(normalized_file):
        input_file = normalized_file
        print("ðŸŽ¯ ä½¿ç”¨è§„èŒƒåŒ–åŽçš„èƒ½æºæ ‡ç­¾æ•°æ®")
    else:
        input_file = original_file
        print("âš ï¸  ä½¿ç”¨åŽŸå§‹æ•°æ®ï¼ˆå»ºè®®å…ˆè¿è¡Œ normalize_energy_tags.pyï¼‰")
    
    if not os.path.exists(input_file):
        print("âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶")
        return
    
    with open(input_file, 'r', encoding='utf-8') as f:
        original_data = json.load(f)
    
    print(f"ðŸ“Š åŽŸå§‹æ•°æ®ï¼š{len(original_data)} ç¯‡æ–‡ç« ")
    
    # ç®€åŒ–æ•°æ®
    simplified_articles = []
    tag_stats = {"total": 0, "min": 100, "max": 0, "counts": []}
    
    for article in original_data:
        simplified = simplify_article_tags(article)
        simplified_articles.append(simplified)
        
        # ç»Ÿè®¡æ ‡ç­¾æ•°é‡
        total_tags = (
            len(simplified.get("basic_info_tags", [])) +
            len(simplified.get("region_tags", [])) +
            len(simplified.get("energy_type_tags", [])) +
            len(simplified.get("business_field_tags", [])) +
            len(simplified.get("importance_tags", []))
        )
        tag_stats["total"] += total_tags
        tag_stats["min"] = min(tag_stats["min"], total_tags)
        tag_stats["max"] = max(tag_stats["max"], total_tags)
        tag_stats["counts"].append(total_tags)
    
    # ä¿å­˜ç®€åŒ–æ•°æ®
    output_file = os.path.join(os.path.dirname(__file__), "ç®€åŒ–æµ‹è¯•æ•°æ®.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(simplified_articles, f, ensure_ascii=False, indent=2)
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"âœ… ç®€åŒ–å®Œæˆï¼š{len(simplified_articles)} ç¯‡æ–‡ç« ")
    print(f"ðŸ“ˆ æ ‡ç­¾ç»Ÿè®¡ï¼š")
    print(f"   å¹³å‡æ ‡ç­¾æ•°ï¼š{tag_stats['total'] / len(simplified_articles):.1f}")
    print(f"   æ ‡ç­¾æ•°èŒƒå›´ï¼š{tag_stats['min']} - {tag_stats['max']}")
    
    # ç»Ÿè®¡æ ‡ç­¾æ•°åˆ†å¸ƒ
    from collections import Counter
    count_dist = Counter(tag_stats["counts"])
    print(f"   æ ‡ç­¾æ•°åˆ†å¸ƒï¼š{dict(sorted(count_dist.items()))}")
    print()
    
    # ç»Ÿè®¡èƒ½æºç±»åž‹åˆ†å¸ƒ
    energy_type_counts = {}
    for article in simplified_articles:
        for energy_type in article.get("energy_type_tags", []):
            energy_type_counts[energy_type] = energy_type_counts.get(energy_type, 0) + 1
    
    print("ðŸ”‹ èƒ½æºç±»åž‹åˆ†å¸ƒï¼š")
    sorted_energy = sorted(energy_type_counts.items(), key=lambda x: x[1], reverse=True)
    for energy_type, count in sorted_energy:
        percentage = (count / len(simplified_articles)) * 100
        print(f"   {energy_type}: {count} ç¯‡ ({percentage:.1f}%)")
    print()
    
    # æ˜¾ç¤ºå‰5ç¯‡ç¤ºä¾‹
    print("ðŸ“‹ ç®€åŒ–åŽçš„æ–‡ç« ç¤ºä¾‹ï¼š")
    for i, article in enumerate(simplified_articles[:5]):
        print(f"\n{i+1}. {article['æ ‡é¢˜'][:50]}...")
        print(f"   ç±»åž‹: {article['æ–‡æ¡£ç±»åž‹']}")
        for key, name in [
            ("basic_info_tags", "åŸºç¡€ä¿¡æ¯"),
            ("region_tags", "åœ°åŸŸ"),
            ("energy_type_tags", "èƒ½æºç±»åž‹"),
            ("business_field_tags", "ä¸šåŠ¡é¢†åŸŸ"),
            ("importance_tags", "é‡è¦æ€§")
        ]:
            tags = article.get(key, [])
            if tags:
                print(f"   {name}: {tags}")
        
        total = sum(len(article.get(key, [])) for key in ["basic_info_tags", "region_tags", "energy_type_tags", "business_field_tags", "importance_tags"])
        print(f"   æ€»æ ‡ç­¾æ•°: {total}")
    
    print(f"\nðŸ’¾ ç®€åŒ–æ•°æ®å·²ä¿å­˜åˆ°ï¼š{output_file}")
    print("\nðŸŽ¯ ç®€åŒ–ç­–ç•¥ï¼š")
    print("   â€¢ åœ°åŸŸæ ‡ç­¾æƒé‡æœ€é«˜ï¼Œä¼˜å…ˆä¿ç•™å…·ä½“åŸŽå¸‚/çœä»½")
    print("   â€¢ èƒ½æºç±»åž‹æ ‡ç­¾æƒé‡é«˜ï¼Œä½¿ç”¨è§„èŒƒåŒ–åŽçš„æ ‡å‡†åˆ†ç±»")  
    print("   â€¢ æ€»æ ‡ç­¾æ•°æŽ§åˆ¶åœ¨3-5ä¸ªï¼Œä¾¿äºŽæµ‹è¯•æŽ¨èæ•ˆæžœ")
    print("   â€¢ ç²¾ç¡®åŒºåˆ†LNGã€PNGç­‰å¤©ç„¶æ°”ç»†åˆ†ç±»åž‹")
    return output_file

if __name__ == "__main__":
    create_simplified_data() 