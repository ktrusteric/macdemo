from fastapi import APIRouter, HTTPException, Depends, Query, status
from typing import List, Optional
from app.models.content import Content, ContentType
from app.services.content_service import ContentService
from app.core.database import get_database
from pydantic import BaseModel
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

router = APIRouter()

class ContentStatsResponse(BaseModel):
    total_count: int
    today_count: int
    this_week_count: int
    announcement_count: int
    news_count: int
    policy_count: int

class ContentListResponse(BaseModel):
    items: List[Content]
    total: int
    page: int
    page_size: int
    has_next: bool

@router.get("/", response_model=ContentListResponse)
async def get_content_list(
    page: int = Query(1, ge=1),
    page_size: int = Query(10, ge=1, le=50),
    content_type: Optional[str] = Query(None, description="å†…å®¹ç±»å‹ç­›é€‰"),
    tag_filters: Optional[str] = Query(None, description="é€—å·åˆ†éš”çš„æ ‡ç­¾åˆ—è¡¨"),
    sort_by: str = Query("latest", regex="^(latest|popularity|relevance)$"),
    search_keyword: Optional[str] = Query(None, description="æœç´¢å…³é”®è¯"),
    db=Depends(get_database)
):
    """è·å–å†…å®¹åˆ—è¡¨ï¼ˆæ”¯æŒç­›é€‰ã€æ’åºã€åˆ†é¡µï¼‰"""
    logger.info(f"ğŸ“‹ å†…å®¹åˆ—è¡¨APIè°ƒç”¨ - page={page}, page_size={page_size}, content_type={content_type}, tag_filters={tag_filters}, sort_by={sort_by}, search_keyword={search_keyword}")
    
    try:
        content_service = ContentService(db)
        
        skip = (page - 1) * page_size
        logger.info(f"ğŸ“„ åˆ†é¡µè®¡ç®— - skip={skip}, limit={page_size}")
        
        # è§£ææ ‡ç­¾ç­›é€‰
        tags = None
        if tag_filters:
            tags = [tag.strip() for tag in tag_filters.split(',')]
            logger.info(f"ğŸ·ï¸ è§£ææ ‡ç­¾ç­›é€‰ - tags={tags}")
        
        # æ ¹æ®æ’åºæ–¹å¼è°ƒç”¨ä¸åŒçš„æ–¹æ³•
        if search_keyword:
            logger.info(f"ğŸ” æœç´¢æ¨¡å¼ - keyword={search_keyword}")
            contents = await content_service.search_content(
                keyword=search_keyword,
                content_type=content_type,
                tags=tags,
                skip=skip,
                limit=page_size
            )
        else:
            logger.info(f"ğŸ“š åˆ—è¡¨æ¨¡å¼ - sort_by={sort_by}")
            contents = await content_service.get_content_list(
                content_type=content_type,
                tags=tags,
                skip=skip,
                limit=page_size,
                sort_by=sort_by
            )
        
        logger.info(f"âœ… è·å–å†…å®¹æˆåŠŸ - è¿”å›{len(contents)}æ¡å†…å®¹")
        
        # æ‰“å°éƒ¨åˆ†å†…å®¹ä¿¡æ¯
        for i, content in enumerate(contents[:3]):  # åªæ‰“å°å‰3æ¡
            logger.info(f"ğŸ“„ å†…å®¹{i+1}: {content.title[:50]}... (ç±»å‹: {content.type})")
            logger.info(f"   basic_info_tags: {getattr(content, 'basic_info_tags', [])}")
            logger.info(f"   region_tags: {getattr(content, 'region_tags', [])}")
        
        # è·å–æ€»æ•°ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
        total_count = await content_service.get_content_count(
            content_type=content_type,
            tags=tags,
            search_keyword=search_keyword
        )
        
        logger.info(f"ğŸ“Š æ€»æ•°ç»Ÿè®¡ - total_count={total_count}")
        
        # è®¡ç®—æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
        has_next = (skip + len(contents)) < total_count
        
        response = ContentListResponse(
            items=contents,
            total=total_count,
            page=page,
            page_size=page_size,
            has_next=has_next
        )
        
        logger.info(f"ğŸ¯ APIè°ƒç”¨å®Œæˆ - è¿”å›å“åº”: items={len(response.items)}, total={response.total}, has_next={response.has_next}")
        return response
        
    except Exception as e:
        logger.error(f"âŒ å†…å®¹åˆ—è¡¨APIé”™è¯¯: {str(e)}")
        logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        import traceback
        logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get content list: {str(e)}"
        )

@router.get("/tags", response_model=List[str])
async def get_available_tags(db=Depends(get_database)):
    """è·å–æ‰€æœ‰å¯ç”¨çš„æ ‡ç­¾"""
    try:
        content_service = ContentService(db)
        tags = await content_service.get_all_tags()
        return tags
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get available tags: {str(e)}"
        )

@router.get("/stats", response_model=ContentStatsResponse)
async def get_content_stats(db=Depends(get_database)):
    """è·å–å†…å®¹ç»Ÿè®¡æ•°æ®"""
    logger.info(f"ğŸ“Š å†…å®¹ç»Ÿè®¡APIè°ƒç”¨")
    
    try:
        content_service = ContentService(db)
        
        # è·å–æ€»æ•°
        total_count = await content_service.get_content_count()
        logger.info(f"ğŸ“„ æ€»å†…å®¹æ•°: {total_count}")
        
        # è·å–ä»Šæ—¥å†…å®¹æ•°ï¼ˆç®€åŒ–å¤„ç†ï¼‰
        today_count = max(1, total_count // 10)
        
        # è·å–æœ¬å‘¨å†…å®¹æ•°
        this_week_count = max(1, total_count // 5)
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        announcement_count = await content_service.get_content_count(content_type="announcement")
        news_count = await content_service.get_content_count(content_type="news")
        policy_count = await content_service.get_content_count(content_type="policy")
        
        logger.info(f"ğŸ“Š ç»Ÿè®¡ç»“æœ - å…¬å‘Š:{announcement_count}, èµ„è®¯:{news_count}, æ”¿ç­–:{policy_count}")
        
        stats = ContentStatsResponse(
            total_count=total_count,
            today_count=today_count,
            this_week_count=this_week_count,
            announcement_count=announcement_count,
            news_count=news_count,
            policy_count=policy_count
        )
        
        logger.info(f"âœ… å†…å®¹ç»Ÿè®¡APIå®Œæˆ")
        return stats
        
    except Exception as e:
        logger.error(f"âŒ å†…å®¹ç»Ÿè®¡APIé”™è¯¯: {str(e)}")
        import traceback
        logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        # è¿”å›é»˜è®¤æ•°æ®è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
        return ContentStatsResponse(
            total_count=0,
            today_count=0,
            this_week_count=0,
            announcement_count=0,
            news_count=0,
            policy_count=0
        )

@router.get("/search", response_model=ContentListResponse)
async def search_content(
    keyword: str = Query(..., min_length=1),
    page: int = Query(1, ge=1),
    page_size: int = Query(10, ge=1, le=50),
    content_type: Optional[str] = Query(None),
    tag_filters: Optional[str] = Query(None),
    db=Depends(get_database)
):
    """æœç´¢å†…å®¹"""
    try:
        content_service = ContentService(db)
        
        skip = (page - 1) * page_size
        tags = None
        if tag_filters:
            tags = [tag.strip() for tag in tag_filters.split(',')]
        
        contents = await content_service.search_content(
            keyword=keyword,
            content_type=content_type,
            tags=tags,
            skip=skip,
            limit=page_size
        )
        
        # è·å–æœç´¢ç»“æœæ€»æ•°
        total_count = await content_service.get_search_count(
            keyword=keyword,
            content_type=content_type,
            tags=tags
        )
        
        has_next = (skip + len(contents)) < total_count
        
        return ContentListResponse(
            items=contents,
            total=total_count,
            page=page,
            page_size=page_size,
            has_next=has_next
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Search failed: {str(e)}"
        )

@router.get("/{content_id}", response_model=Content)
async def get_content_detail(
    content_id: str,
    db=Depends(get_database)
):
    """è·å–å†…å®¹è¯¦æƒ…"""
    try:
        content_service = ContentService(db)
        content = await content_service.get_content_by_id(content_id)
        
        if not content:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Content not found"
            )
        
        return content
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )

@router.post("/{content_id}/view")
async def record_content_view(
    content_id: str,
    db=Depends(get_database)
):
    """è®°å½•å†…å®¹æµè§ˆï¼ˆå¢åŠ æµè§ˆæ¬¡æ•°ï¼‰"""
    try:
        content_service = ContentService(db)
        await content_service.increment_view_count(content_id)
        return {"success": True, "message": "View recorded successfully"}
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to record view: {str(e)}"
        )

@router.post("/", response_model=Content)
async def create_content(
    content: Content,
    db=Depends(get_database)
):
    """åˆ›å»ºå†…å®¹"""
    try:
        content_service = ContentService(db)
        created_content = await content_service.create_content(content)
        return created_content
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )

@router.post("/recommend", response_model=ContentListResponse)
async def recommend_content(
    request: dict,
    db=Depends(get_database)
):
    """åŸºäºç”¨æˆ·æ ‡ç­¾æ¨èå†…å®¹"""
    logger.info(f"ğŸ¯ å†…å®¹æ¨èAPIè°ƒç”¨ - request: {request}")
    
    try:
        user_tags = request.get('user_tags', [])
        limit = request.get('limit', 10)
        
        logger.info(f"ğŸ·ï¸ ç”¨æˆ·æ ‡ç­¾: {user_tags}")
        logger.info(f"ğŸ“Š æ¨èæ•°é‡é™åˆ¶: {limit}")
        
        from app.services.recommendation_service import RecommendationService
        recommendation_service = RecommendationService(db)
        
        # è¿™é‡Œå…ˆå®ç°ç®€å•çš„æ ‡ç­¾åŒ¹é…æ¨è
        content_service = ContentService(db)
        
        # è§£ææ ‡ç­¾åˆ†ç±»
        basic_info_tags = []
        region_tags = []
        energy_type_tags = []
        business_field_tags = []
        beneficiary_tags = []
        policy_measure_tags = []
        importance_tags = []
        
        for tag in user_tags:
            if ':' in tag:
                category, name = tag.split(':', 1)
                if category == 'basic_info':
                    basic_info_tags.append(name)
                elif category == 'region':
                    region_tags.append(name)
                elif category == 'energy_type':
                    energy_type_tags.append(name)
                elif category == 'business_field':
                    business_field_tags.append(name)
                elif category == 'beneficiary':
                    beneficiary_tags.append(name)
                elif category == 'policy_measure':
                    policy_measure_tags.append(name)
                elif category == 'importance':
                    importance_tags.append(name)
        
        logger.info(f"ğŸ“‹ è§£ææ ‡ç­¾åˆ†ç±»:")
        logger.info(f"  basic_info_tags: {basic_info_tags}")
        logger.info(f"  region_tags: {region_tags}")
        logger.info(f"  energy_type_tags: {energy_type_tags}")
        logger.info(f"  business_field_tags: {business_field_tags}")
        logger.info(f"  beneficiary_tags: {beneficiary_tags}")
        logger.info(f"  policy_measure_tags: {policy_measure_tags}")
        logger.info(f"  importance_tags: {importance_tags}")
        
        # è·å–åŒ¹é…å†…å®¹
        contents = await content_service.get_content_by_tags(
            basic_info_tags=basic_info_tags,
            region_tags=region_tags,
            energy_type_tags=energy_type_tags,
            business_field_tags=business_field_tags,
            beneficiary_tags=beneficiary_tags,
            policy_measure_tags=policy_measure_tags,
            importance_tags=importance_tags,
            limit=limit
        )
        
        logger.info(f"âœ… æ¨èå†…å®¹è·å–æˆåŠŸ - è¿”å›{len(contents)}æ¡å†…å®¹")
        
        # æ‰“å°æ¨èå†…å®¹è¯¦æƒ…
        for i, content in enumerate(contents[:3]):
            logger.info(f"ğŸ“„ æ¨èå†…å®¹{i+1}: {content.title[:50]}...")
            logger.info(f"   ç±»å‹: {content.type}")
            logger.info(f"   basic_info_tags: {getattr(content, 'basic_info_tags', [])}")
            logger.info(f"   region_tags: {getattr(content, 'region_tags', [])}")
        
        return ContentListResponse(
            items=contents,
            total=len(contents),
            page=1,
            page_size=limit,
            has_next=False
        )
        
    except Exception as e:
        logger.error(f"âŒ å†…å®¹æ¨èAPIé”™è¯¯: {str(e)}")
        import traceback
        logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        # è¿”å›ç©ºç»“æœè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
        return ContentListResponse(
            items=[],
            total=0,
            page=1,
            page_size=limit if 'limit' in locals() else 10,
            has_next=False
        ) 