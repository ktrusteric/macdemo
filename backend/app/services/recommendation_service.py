from typing import List, Dict, Any
from pymongo.database import Database
from datetime import datetime, timedelta
from app.models.user import UserTags, UserTag
from app.models.content import Content
from app.services.user_service import UserService
from app.services.content_service import ContentService

class RecommendationService:
    def __init__(self, database: Database):
        self.db = database
        self.user_service = UserService(database)
        self.content_service = ContentService(database)
        self.user_behavior_collection = self.db.user_behavior

    async def get_user_recommendations(
        self,
        user_id: str,
        skip: int = 0,
        limit: int = 10
    ) -> List[Content]:
        """è·å–ç”¨æˆ·ä¸ªæ€§åŒ–æ¨èå†…å®¹"""
        try:
            # è·å–ç”¨æˆ·æ ‡ç­¾
            user_tags = await self.user_service.get_user_tags(user_id)
            
            if not user_tags or not user_tags.tags:
                # å¦‚æœç”¨æˆ·æ²¡æœ‰æ ‡ç­¾ï¼Œå°è¯•ç¡®ä¿ç”¨æˆ·æœ‰æ ‡ç­¾
                try:
                    user_tags = await self.user_service.ensure_user_has_tags(user_id)
                except:
                    # å¦‚æœä»ç„¶æ— æ³•è·å–æ ‡ç­¾ï¼Œè¿”å›æœ€æ–°å†…å®¹
                    print(f"ç”¨æˆ· {user_id} æ— æ³•è·å–æ ‡ç­¾ï¼Œè¿”å›æœ€æ–°å†…å®¹")
                    return await self.content_service.get_content_list(skip=skip, limit=limit)
            
            print(f"ğŸ¯ æ¨èæœåŠ¡ä¸ºç”¨æˆ· {user_id} æ‰¾åˆ° {len(user_tags.tags)} ä¸ªæ ‡ç­¾")
            
            # åŸºäºç”¨æˆ·è¡Œä¸ºè°ƒæ•´æ ‡ç­¾æƒé‡
            adjusted_tags = await self.adjust_tag_weights_by_behavior(user_id, user_tags.tags)
            
            # æå–ç”¨æˆ·æ‰€æœ‰æ ‡ç­¾åç§°
            tag_names = [tag.name for tag in adjusted_tags]
            print(f"ğŸ“‹ æ¨èæœåŠ¡ä½¿ç”¨æ ‡ç­¾: {tag_names}")
            
            # æ ¹æ®ç”¨æˆ·æ ‡ç­¾è·å–æ¨èå†…å®¹
            recommended_content = await self.content_service.get_content_by_user_tags(
                user_tags=tag_names,
                skip=skip,
                limit=limit
            )
            
            print(f"ğŸ“Š æ ¹æ®æ ‡ç­¾æ‰¾åˆ° {len(recommended_content)} æ¡åŒ¹é…å†…å®¹")
            
            # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°ï¼ˆä½¿ç”¨ä¼˜åŒ–çš„æƒé‡åˆ†çº§ç³»ç»Ÿï¼‰
            for content in recommended_content:
                content.relevance_score = await self.calculate_content_relevance_score_v2(
                    UserTags(user_id=user_id, tags=adjusted_tags),
                    content
                )
            
            # æŒ‰ç›¸å…³æ€§æ’åº
            recommended_content.sort(key=lambda x: x.relevance_score or 0, reverse=True)
            
            return recommended_content
        except Exception as e:
            print(f"âŒ æ¨èæœåŠ¡é”™è¯¯: {str(e)}")
            raise Exception(f"Failed to get user recommendations: {str(e)}")

    async def record_user_behavior(
        self,
        user_id: str,
        action: str,
        content_id: str,
        duration: int = None
    ) -> None:
        """è®°å½•ç”¨æˆ·è¡Œä¸º"""
        try:
            behavior_data = {
                "user_id": user_id,
                "action": action,
                "content_id": content_id,
                "timestamp": datetime.utcnow(),
                "duration": duration
            }
            
            await self.user_behavior_collection.insert_one(behavior_data)
            
            # å¦‚æœæ˜¯æŸ¥çœ‹è¡Œä¸ºï¼Œæ›´æ–°å†…å®¹çš„æµè§ˆæ¬¡æ•°
            if action == 'view':
                await self.content_service.increment_view_count(content_id)
                
        except Exception as e:
            raise Exception(f"Failed to record user behavior: {str(e)}")

    async def adjust_tag_weights_by_behavior(
        self,
        user_id: str,
        user_tags: List[UserTag]
    ) -> List[UserTag]:
        """æ ¹æ®ç”¨æˆ·è¡Œä¸ºè°ƒæ•´æ ‡ç­¾æƒé‡"""
        try:
            # è·å–æœ€è¿‘30å¤©çš„ç”¨æˆ·è¡Œä¸º
            thirty_days_ago = datetime.utcnow() - timedelta(days=30)
            
            behaviors = await self.user_behavior_collection.find({
                "user_id": user_id,
                "timestamp": {"$gte": thirty_days_ago}
            }).to_list(length=None)
            
            if not behaviors:
                return user_tags
            
            # ç»Ÿè®¡æ¯ä¸ªæ ‡ç­¾çš„è¡Œä¸ºæ¬¡æ•°
            tag_behavior_counts = {}
            
            for behavior in behaviors:
                content = await self.content_service.get_content_by_id(behavior["content_id"])
                if not content:
                    continue
                    
                # æ”¶é›†å†…å®¹çš„æ‰€æœ‰æ ‡ç­¾
                content_tags = (
                    content.basic_info_tags +
                    content.region_tags +
                    content.energy_type_tags +
                    content.business_field_tags +
                    content.beneficiary_tags +
                    content.policy_measure_tags +
                    content.importance_tags
                )
                
                # ä¸ºæ¯ä¸ªæ ‡ç­¾å¢åŠ è¡Œä¸ºè®¡æ•°
                for tag_name in content_tags:
                    if tag_name not in tag_behavior_counts:
                        tag_behavior_counts[tag_name] = 0
                    
                    # ä¸åŒè¡Œä¸ºçš„æƒé‡ä¸åŒ
                    weight_multiplier = {
                        'view': 1.0,
                        'click': 1.5,
                        'like': 2.0,
                        'share': 3.0
                    }.get(behavior["action"], 1.0)
                    
                    tag_behavior_counts[tag_name] += weight_multiplier
            
            # è°ƒæ•´ç”¨æˆ·æ ‡ç­¾æƒé‡
            adjusted_tags = []
            for tag in user_tags:
                new_weight = tag.weight
                
                # æ ¹æ®è¡Œä¸ºé¢‘æ¬¡è°ƒæ•´æƒé‡
                if tag.name in tag_behavior_counts:
                    behavior_count = tag_behavior_counts[tag.name]
                    # è¡Œä¸ºè¶Šå¤šï¼Œæƒé‡å¢åŠ è¶Šå¤šï¼ˆä½†æœ‰ä¸Šé™ï¼‰
                    weight_boost = min(behavior_count * 0.1, 2.0)
                    new_weight = min(tag.weight + weight_boost, 10.0)
                
                adjusted_tags.append(UserTag(
                    category=tag.category,
                    name=tag.name,
                    weight=new_weight,
                    source=tag.source,
                    created_at=tag.created_at
                ))
            
            return adjusted_tags
            
        except Exception as e:
            raise Exception(f"Failed to adjust tag weights: {str(e)}")

    async def get_user_behavior_insights(self, user_id: str) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·è¡Œä¸ºæ´å¯Ÿ"""
        try:
            seven_days_ago = datetime.utcnow() - timedelta(days=7)
            
            # è·å–æœ€è¿‘7å¤©çš„è¡Œä¸ºæ•°æ®
            recent_behaviors = await self.user_behavior_collection.find({
                "user_id": user_id,
                "timestamp": {"$gte": seven_days_ago}
            }).to_list(length=None)
            
            # ç»Ÿè®¡å„ç±»è¡Œä¸º
            behavior_stats = {
                'view': 0,
                'click': 0,
                'like': 0,
                'share': 0
            }
            
            total_reading_time = 0
            content_types = {}
            
            for behavior in recent_behaviors:
                action = behavior.get('action', 'view')
                if action in behavior_stats:
                    behavior_stats[action] += 1
                
                if behavior.get('duration'):
                    total_reading_time += behavior['duration']
                
                # ç»Ÿè®¡æµè§ˆçš„å†…å®¹ç±»å‹
                content = await self.content_service.get_content_by_id(behavior["content_id"])
                if content:
                    content_type = content.type
                    content_types[content_type] = content_types.get(content_type, 0) + 1
            
            # è®¡ç®—æ´»è·ƒåº¦è¯„åˆ†
            activity_score = (
                behavior_stats['view'] * 1 +
                behavior_stats['click'] * 2 +
                behavior_stats['like'] * 3 +
                behavior_stats['share'] * 4
            )
            
            return {
                'behavior_stats': behavior_stats,
                'total_reading_time': total_reading_time,
                'average_reading_time': total_reading_time / max(behavior_stats['view'], 1),
                'preferred_content_types': content_types,
                'activity_score': activity_score,
                'engagement_level': self._calculate_engagement_level(activity_score)
            }
            
        except Exception as e:
            raise Exception(f"Failed to get user insights: {str(e)}")

    def _calculate_engagement_level(self, activity_score: int) -> str:
        """è®¡ç®—ç”¨æˆ·å‚ä¸åº¦ç­‰çº§"""
        if activity_score >= 100:
            return 'high'
        elif activity_score >= 50:
            return 'medium'
        elif activity_score >= 20:
            return 'low'
        else:
            return 'minimal'

    async def calculate_content_relevance_score_v2(
        self,
        user_tags: UserTags,
        content: Content
    ) -> float:
        """è®¡ç®—å†…å®¹ä¸ç”¨æˆ·çš„ç›¸å…³æ€§åˆ†æ•°V2 - æ ‡ç­¾æƒé‡ä¼˜å…ˆï¼Œæ—¶é—´è°ƒèŠ‚"""
        
        if not user_tags or not user_tags.tags:
            return 0.0
        
        # æ”¶é›†å†…å®¹çš„æ‰€æœ‰æ ‡ç­¾
        content_all_tags = self._get_all_content_tags(content)
        
        if not content_all_tags:
            return 0.0
        
        # ğŸ”¥ æƒé‡ç±»åˆ«ä¼˜å…ˆçº§é…ç½®
        WEIGHT_MULTIPLIERS = {
            "region": 3.0,      # åœ°åŸŸæ ‡ç­¾ - æœ€é«˜ä¼˜å…ˆçº§
            "city": 3.0,        # åŸå¸‚æ ‡ç­¾ - æœ€é«˜ä¼˜å…ˆçº§  
            "province": 2.0,    # çœä»½æ ‡ç­¾
            "energy_type": 2.5, # èƒ½æºç±»å‹æ ‡ç­¾ - ç¬¬äºŒä¼˜å…ˆçº§
            "basic_info": 1.0,  # åŸºç¡€ä¿¡æ¯æ ‡ç­¾
            "business_field": 0.8,  # ä¸šåŠ¡é¢†åŸŸæ ‡ç­¾
            "policy_measure": 0.8,  # æ”¿ç­–æªæ–½æ ‡ç­¾
            "beneficiary": 0.6,     # å—ç›Šä¸»ä½“æ ‡ç­¾
            "importance": 0.6       # é‡è¦æ€§æ ‡ç­¾
        }
        
        # è®¡ç®—æ ‡ç­¾æƒé‡åˆ†æ•°
        total_score = 0.0
        matched_tags = 0
        highest_tag_weight = 0.0  # ğŸ”¥ è®°å½•æœ€é«˜æ ‡ç­¾æƒé‡
        energy_type_matched = False  # ğŸ”¥ è®°å½•æ˜¯å¦åŒ¹é…èƒ½æºç±»å‹
        energy_type_score = 0.0     # ğŸ”¥ è®°å½•èƒ½æºç±»å‹å¾—åˆ†
        
        for user_tag in user_tags.tags:
            tag_name = user_tag.name
            tag_category = user_tag.category
            tag_weight = getattr(user_tag, 'weight', 1.0)
            
            # æ£€æŸ¥æ ‡ç­¾æ˜¯å¦åœ¨å†…å®¹ä¸­
            if tag_name in content_all_tags:
                matched_tags += 1
                
                # è·å–æƒé‡ä¹˜æ³•å™¨
                multiplier = WEIGHT_MULTIPLIERS.get(tag_category, 1.0)
                
                # ğŸ”¥ è®¡ç®—æœ€ç»ˆå¾—åˆ†ï¼šç”¨æˆ·æ ‡ç­¾æƒé‡ Ã— æƒé‡ä¹˜æ³•å™¨
                tag_score = tag_weight * multiplier
                
                # è®°å½•æœ€é«˜æƒé‡æ ‡ç­¾
                if tag_weight > highest_tag_weight:
                    highest_tag_weight = tag_weight
                
                # ğŸ¯ è®°å½•èƒ½æºç±»å‹åŒ¹é…
                if tag_category == "energy_type":
                    energy_type_matched = True
                    energy_type_score = tag_score
                    print(f"ğŸ” èƒ½æºæ ‡ç­¾æƒé‡è®¡ç®—: {tag_name} = {tag_weight} Ã— {multiplier} = {tag_score}")
                
                total_score += tag_score
        
        # ğŸ¯ ç²¾å‡†æ ‡ç­¾åŒ¹é…å¥–åŠ±ç³»ç»Ÿ
        if energy_type_matched and highest_tag_weight >= 4.0:
            # é«˜æƒé‡èƒ½æºç±»å‹æ ‡ç­¾é¢å¤–å¥–åŠ±
            precision_bonus = energy_type_score * 0.8  # ğŸ”¥ æå‡åˆ°80%ç²¾å‡†åŒ¹é…å¥–åŠ±
            total_score += precision_bonus
            print(f"ğŸ¯ ç²¾å‡†èƒ½æºæ ‡ç­¾å¥–åŠ±: +{precision_bonus:.2f} (æ€»åˆ†: {total_score:.2f})")
            
            # ğŸ¯ èƒ½æºç±»å‹ä¼˜å…ˆæƒï¼šå¦‚æœç”¨æˆ·æœ‰é«˜æƒé‡èƒ½æºæ ‡ç­¾ä¸”å†…å®¹ç²¾å‡†åŒ¹é…ï¼Œé¢å¤–å¥–åŠ±
            if highest_tag_weight >= 5.0:
                super_precision_bonus = energy_type_score * 0.3  # 30%è¶…çº§ç²¾å‡†å¥–åŠ±
                total_score += super_precision_bonus
                print(f"ğŸ”¥ è¶…çº§ç²¾å‡†èƒ½æºæ ‡ç­¾å¥–åŠ±: +{super_precision_bonus:.2f} (æ€»åˆ†: {total_score:.2f})")
        
        # ğŸ¯ æƒé‡ä¼˜å…ˆé€»è¾‘ï¼šæ ‡ç­¾æƒé‡åˆ†å±‚ + æ—¶é—´è°ƒèŠ‚
        if highest_tag_weight >= 4.0:
            # é«˜æƒé‡æ ‡ç­¾ï¼ˆâ‰¥4.0ï¼‰ï¼šæ ‡ç­¾æƒé‡ä¸ºä¸»ï¼Œæ—¶é—´ä¸ºè¾…
            time_factor = self._calculate_time_factor_light(content.publish_time) if hasattr(content, 'publish_time') and content.publish_time else 1.0
            final_score = total_score + (time_factor - 1.0) * 2.0  # æ—¶é—´åªä½œä¸ºå¾®è°ƒå› å­
        elif highest_tag_weight >= 2.0:
            # ä¸­æƒé‡æ ‡ç­¾ï¼ˆ2.0-4.0ï¼‰ï¼šå¹³è¡¡æƒé‡å’Œæ—¶é—´
            time_factor = self._calculate_time_factor(content.publish_time) if hasattr(content, 'publish_time') and content.publish_time else 1.0
            final_score = total_score * (0.8 + 0.2 * time_factor)  # æƒé‡80%ï¼Œæ—¶é—´20%
        else:
            # ä½æƒé‡æ ‡ç­¾ï¼ˆ<2.0ï¼‰ï¼šæ—¶é—´æƒé‡ç›¸å¯¹è¾ƒé«˜
            time_factor = self._calculate_time_factor(content.publish_time) if hasattr(content, 'publish_time') and content.publish_time else 1.0
            final_score = total_score * time_factor  # ä¼ ç»Ÿçš„æ—¶é—´æƒé‡
        
        return final_score

    def _calculate_time_factor_light(self, publish_time: str) -> float:
        """è®¡ç®—è½»é‡æ—¶æ•ˆæ€§å› å­ï¼ˆç”¨äºé«˜æƒé‡æ ‡ç­¾çš„å¾®è°ƒï¼‰"""
        try:
            publish_date = datetime.fromisoformat(publish_time.replace('Z', '+00:00'))
            now = datetime.utcnow().replace(tzinfo=publish_date.tzinfo)
            days_diff = (now - publish_date).days
            
            # é«˜æƒé‡æ ‡ç­¾çš„æ—¶é—´å› å­èŒƒå›´ç¼©å°ï¼š0.9-1.1
            if days_diff <= 3:
                return 1.1  # 3å¤©å†…å¾®è°ƒåŠ åˆ†
            elif days_diff <= 7:
                return 1.0  # ä¸€å‘¨å†…æ ‡å‡†åˆ†
            elif days_diff <= 30:
                return 0.95  # ä¸€æœˆå†…è½»å¾®å‡åˆ†
            else:
                return 0.9   # è¶…è¿‡ä¸€æœˆå°å¹…å‡åˆ†
        except:
            return 1.0  # é»˜è®¤å€¼

    def _calculate_time_factor(self, publish_time: str) -> float:
        """è®¡ç®—æ—¶æ•ˆæ€§å› å­"""
        try:
            publish_date = datetime.fromisoformat(publish_time.replace('Z', '+00:00'))
            now = datetime.utcnow().replace(tzinfo=publish_date.tzinfo)
            days_diff = (now - publish_date).days
            
            # 7å¤©å†…çš„å†…å®¹ç»™äºˆæ»¡åˆ†
            if days_diff <= 7:
                return 1.0
            # 30å¤©å†…çš„å†…å®¹é€æ¸é™æƒ
            elif days_diff <= 30:
                return 1.0 - (days_diff - 7) * 0.02  # æ¯å¤©é™æƒ2%
            # è¶…è¿‡30å¤©çš„å†…å®¹ç»™äºˆåŸºç¡€åˆ†
            else:
                return 0.5
        except:
            return 0.8  # é»˜è®¤å€¼

    async def get_trending_content(
        self,
        skip: int = 0,
        limit: int = 10
    ) -> List[Content]:
        """è·å–çƒ­é—¨å†…å®¹"""
        try:
            # è·å–æœ€æ–°çš„é‡è¦å†…å®¹
            pipeline = [
                {
                    "$match": {
                        "$or": [
                            {"importance_tags": {"$in": ["å›½å®¶çº§", "æƒå¨å‘å¸ƒ", "é‡è¦æ”¿ç­–"]}},
                            {"basic_info_tags": {"$in": ["æ”¿ç­–æ³•è§„", "è¡Œä¸šèµ„è®¯"]}}
                        ]
                    }
                },
                {"$sort": {"publish_date": -1}},
                {"$skip": skip},
                {"$limit": limit}
            ]
            
            contents = []
            async for document in self.content_service.collection.aggregate(pipeline):
                document['id'] = str(document['_id'])
                contents.append(Content(**document))
            
            return contents
        except Exception as e:
            raise Exception(f"Failed to get trending content: {str(e)}")

    async def get_similar_content(
        self,
        content_id: str,
        limit: int = 5
    ) -> List[Content]:
        """è·å–ç›¸ä¼¼å†…å®¹"""
        try:
            # è·å–åŸå§‹å†…å®¹
            original_content = await self.content_service.get_content_by_id(content_id)
            if not original_content:
                return []
            
            # æ”¶é›†åŸå§‹å†…å®¹çš„æ‰€æœ‰æ ‡ç­¾
            all_tags = (
                original_content.basic_info_tags +
                original_content.region_tags +
                original_content.energy_type_tags +
                original_content.business_field_tags +
                original_content.beneficiary_tags +
                original_content.policy_measure_tags +
                original_content.importance_tags
            )
            
            if not all_tags:
                return []
            
            # æŸ¥æ‰¾å…·æœ‰ç›¸ä¼¼æ ‡ç­¾çš„å†…å®¹
            similar_content = await self.content_service.get_content_by_user_tags(
                user_tags=all_tags,
                skip=0,
                limit=limit + 1  # å¤šå–ä¸€ä¸ªï¼Œå› ä¸ºå¯èƒ½åŒ…å«åŸå§‹å†…å®¹
            )
            
            # è¿‡æ»¤æ‰åŸå§‹å†…å®¹
            return [c for c in similar_content if c.id != content_id][:limit]
        except Exception as e:
            raise Exception(f"Failed to get similar content: {str(e)}")

    async def get_tiered_recommendations(
        self,
        user_id: str,
        primary_limit: int = 6,
        secondary_limit: int = 4
    ) -> dict:
        """è·å–åˆ†çº§æ¨èå†…å®¹ï¼šç²¾å‡†æ¨èï¼ˆä¸€çº§æƒé‡ï¼‰+ æ‰©å±•æ¨èï¼ˆäºŒçº§æƒé‡ï¼‰"""
        try:
            # è·å–ç”¨æˆ·æ ‡ç­¾
            user_tags = await self.user_service.get_user_tags(user_id)
            
            if not user_tags or not user_tags.tags:
                try:
                    user_tags = await self.user_service.ensure_user_has_tags(user_id)
                except:
                    return {
                        "primary_recommendations": [],
                        "secondary_recommendations": [],
                        "total_primary": 0,
                        "total_secondary": 0
                    }
            
            print(f"ğŸ¯ åˆ†çº§æ¨èä¸ºç”¨æˆ· {user_id} å¤„ç† {len(user_tags.tags)} ä¸ªæ ‡ç­¾")
            
            # åˆ†ç¦»ä¸€çº§å’ŒäºŒçº§æƒé‡æ ‡ç­¾
            primary_tags = []  # åœ°åŸŸã€èƒ½æºç±»å‹
            secondary_tags = []  # å…¶ä»–æ ‡ç­¾
            
            for tag in user_tags.tags:
                if tag.category in ["region", "energy_type"]:
                    primary_tags.append(tag.name)
                else:
                    secondary_tags.append(tag.name)
            
            print(f"ğŸ“ ä¸€çº§æƒé‡æ ‡ç­¾ï¼ˆåœ°åŸŸ+èƒ½æºï¼‰: {primary_tags}")
            print(f"ğŸ“‹ äºŒçº§æƒé‡æ ‡ç­¾ï¼ˆä¸šåŠ¡+æ”¿ç­–ç­‰ï¼‰: {secondary_tags}")
            
            # è·å–ç²¾å‡†æ¨èï¼ˆåŸºäºä¸€çº§æƒé‡æ ‡ç­¾ï¼‰
            primary_recommendations = []
            if primary_tags:
                primary_recommendations = await self.content_service.get_content_by_user_tags(
                    user_tags=primary_tags,
                    skip=0,
                    limit=primary_limit
                )
                
                # è®¡ç®—ç²¾å‡†æ¨èçš„ç›¸å…³æ€§åˆ†æ•°
                for content in primary_recommendations:
                    content.relevance_score = await self.calculate_primary_relevance_score(
                        primary_tags, content
                    )
                
                primary_recommendations.sort(key=lambda x: x.relevance_score or 0, reverse=True)
            
            # è·å–æ‰©å±•æ¨èï¼ˆåŸºäºäºŒçº§æƒé‡æ ‡ç­¾ï¼Œæ’é™¤å·²æ¨èçš„å†…å®¹ï¼‰
            secondary_recommendations = []
            if secondary_tags:
                # è·å–å·²æ¨èçš„å†…å®¹IDï¼Œé¿å…é‡å¤
                recommended_ids = {rec.id for rec in primary_recommendations}
                
                all_secondary = await self.content_service.get_content_by_user_tags(
                    user_tags=secondary_tags,
                    skip=0,
                    limit=secondary_limit + len(recommended_ids)  # å¤šå–ä¸€äº›ä»¥å¤‡ç­›é€‰
                )
                
                # ç­›é€‰æ‰å·²åœ¨ç²¾å‡†æ¨èä¸­çš„å†…å®¹
                secondary_recommendations = [
                    content for content in all_secondary 
                    if content.id not in recommended_ids
                ][:secondary_limit]
                
                # è®¡ç®—æ‰©å±•æ¨èçš„ç›¸å…³æ€§åˆ†æ•°
                for content in secondary_recommendations:
                    content.relevance_score = await self.calculate_secondary_relevance_score(
                        secondary_tags, content
                    )
                
                secondary_recommendations.sort(key=lambda x: x.relevance_score or 0, reverse=True)
            
            print(f"âœ… åˆ†çº§æ¨èå®Œæˆ: ç²¾å‡†{len(primary_recommendations)}ç¯‡ï¼Œæ‰©å±•{len(secondary_recommendations)}ç¯‡")
            
            return {
                "primary_recommendations": primary_recommendations,
                "secondary_recommendations": secondary_recommendations,
                "total_primary": len(primary_recommendations),
                "total_secondary": len(secondary_recommendations),
                "primary_tags_used": primary_tags,
                "secondary_tags_used": secondary_tags
            }
            
        except Exception as e:
            print(f"âŒ åˆ†çº§æ¨èæœåŠ¡é”™è¯¯: {str(e)}")
            raise Exception(f"Failed to get tiered recommendations: {str(e)}")

    async def calculate_primary_relevance_score(
        self,
        primary_tags: List[str],
        content: Content
    ) -> float:
        """è®¡ç®—ç²¾å‡†æ¨èçš„ç›¸å…³æ€§åˆ†æ•°ï¼ˆä»…åŸºäºä¸€çº§æƒé‡æ ‡ç­¾ï¼‰"""
        try:
            if not primary_tags:
                return 0.0
            
            total_score = 0.0
            matched_tags = 0
            
            # åœ°åŸŸæ ‡ç­¾åŒ¹é…ï¼ˆæƒé‡Ã—3.0ï¼‰
            region_matches = len([tag for tag in content.region_tags if tag in primary_tags])
            if region_matches > 0:
                total_score += region_matches * 3.0
                matched_tags += region_matches
            
            # èƒ½æºç±»å‹æ ‡ç­¾åŒ¹é…ï¼ˆæƒé‡Ã—2.5ï¼‰
            energy_matches = len([tag for tag in content.energy_type_tags if tag in primary_tags])
            if energy_matches > 0:
                total_score += energy_matches * 2.5
                matched_tags += energy_matches
            
            if matched_tags == 0:
                return 0.0
            
            # æ—¶æ•ˆæ€§å› å­
            time_factor = self._calculate_time_factor(content.publish_time)
            
            # ç‰¹æ®Šå¥–åŠ±ï¼šåœ°åŸŸ+èƒ½æºç±»å‹åŒé‡åŒ¹é…
            bonus_factor = 1.0
            if region_matches > 0 and energy_matches > 0:
                bonus_factor = 1.5  # åŒé‡åŒ¹é…50%å¥–åŠ±
            
            # ç²¾å‡†æ¨èåˆ†æ•°è®¡ç®—
            final_score = (total_score * time_factor * bonus_factor) / 10.0
            
            return min(final_score, 1.0)
        except Exception as e:
            return 0.0

    async def calculate_secondary_relevance_score(
        self,
        secondary_tags: List[str],
        content: Content
    ) -> float:
        """è®¡ç®—æ‰©å±•æ¨èçš„ç›¸å…³æ€§åˆ†æ•°ï¼ˆåŸºäºäºŒçº§æƒé‡æ ‡ç­¾ï¼‰"""
        try:
            if not secondary_tags:
                return 0.0
            
            total_score = 0.0
            matched_tags = 0
            
            # äºŒçº§æƒé‡æ ‡ç­¾åŒ¹é…è®¡ç®—
            tag_categories = [
                ("basic_info_tags", 1.0),
                ("business_field_tags", 0.7),
                ("policy_measure_tags", 0.7),
                ("importance_tags", 0.5),
                ("beneficiary_tags", 0.5)
            ]
            
            for content_field, weight in tag_categories:
                content_tags = getattr(content, content_field, [])
                matches = len([tag for tag in content_tags if tag in secondary_tags])
                if matches > 0:
                    total_score += matches * weight
                    matched_tags += matches
            
            if matched_tags == 0:
                return 0.0
            
            # æ—¶æ•ˆæ€§å› å­
            time_factor = self._calculate_time_factor(content.publish_time)
            
            # æ‰©å±•æ¨èåˆ†æ•°è®¡ç®—ï¼ˆç›¸å¯¹ä¿å®ˆï¼Œé¿å…å¹²æ‰°ï¼‰
            final_score = (total_score * time_factor) / 8.0
            
            return min(final_score, 0.8)  # æ‰©å±•æ¨èæœ€é«˜åˆ†æ•°é™åˆ¶åœ¨0.8
        except Exception as e:
            return 0.0

    async def get_smart_recommendations(
        self,
        user_id: str,
        skip: int = 0,
        limit: int = 10
    ) -> List[Content]:
        """
        ğŸ”¥ æ™ºèƒ½æ¨èç®—æ³•ï¼šç²¾å‡†æƒé‡åŒ¹é…ä¼˜å…ˆ + æ—¶é—´æ’åº
        
        ç®—æ³•é€»è¾‘ï¼š
        1. æŒ‰æ ‡ç­¾æƒé‡ç²¾å‡†åº¦åˆ†å±‚
        2. æ¯å±‚å†…éƒ¨æŒ‰æ—¶é—´æ’åº
        3. é«˜æƒé‡ç²¾å‡†åŒ¹é…ä¼˜å…ˆæ˜¾ç¤º
        4. çœŸæ­£å®ç°åƒäººåƒé¢æ¨è
        
        Args:
            user_id: ç”¨æˆ·ID
            skip: è·³è¿‡æ•°é‡
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            List[Content]: æ™ºèƒ½æ¨èçš„å†…å®¹åˆ—è¡¨
        """
        try:
            print(f"ğŸ§  å¼€å§‹æ™ºèƒ½æ¨è - ç”¨æˆ·: {user_id}")
            
            # è·å–ç”¨æˆ·æ ‡ç­¾
            user_tags = await self.user_service.get_user_tags(user_id)
            
            if not user_tags or not user_tags.tags:
                try:
                    user_tags = await self.user_service.ensure_user_has_tags(user_id)
                except:
                    print(f"âŒ ç”¨æˆ· {user_id} æ— æ ‡ç­¾ï¼Œè¿”å›æœ€æ–°å†…å®¹")
                    return await self.content_service.get_content_list(skip=skip, limit=limit)
            
            print(f"ğŸ·ï¸ ç”¨æˆ·æ ‡ç­¾æ•°é‡: {len(user_tags.tags)}")
            
            # æ ¹æ®ç”¨æˆ·è¡Œä¸ºè°ƒæ•´æ ‡ç­¾æƒé‡
            adjusted_tags = await self.adjust_tag_weights_by_behavior(user_id, user_tags.tags)
            
            # æŒ‰æ ‡ç­¾æƒé‡æ’åºï¼Œæƒé‡é«˜çš„ä¼˜å…ˆ
            adjusted_tags.sort(key=lambda x: x.weight, reverse=True)
            
            # ğŸ”¥ åˆ†å±‚æ¨èç­–ç•¥
            recommendations = []
            used_content_ids = set()
            
            print(f"ğŸ¯ å¼€å§‹åˆ†å±‚æ¨èï¼Œåˆå§‹used_content_ids: {len(used_content_ids)}")
            
            # ç¬¬ä¸€å±‚ï¼šæœ€é«˜æƒé‡æ ‡ç­¾ç²¾å‡†åŒ¹é…ï¼ˆæƒé‡ >= 4.0ï¼‰
            high_weight_tags = [tag for tag in adjusted_tags if tag.weight >= 4.0]
            if high_weight_tags:
                print(f"ğŸ”¥ ç¬¬ä¸€å±‚ï¼šé«˜æƒé‡æ ‡ç­¾ ({len(high_weight_tags)}ä¸ª)")
                for tag in high_weight_tags:
                    print(f"   ğŸ·ï¸ {tag.name} (æƒé‡: {tag.weight})")
                
                print(f"ğŸ” ç¬¬ä¸€å±‚å‰used_content_ids: {used_content_ids}")
                first_tier = await self._get_precise_content_by_tags(
                    high_weight_tags,
                    used_content_ids,
                    max_per_tag=3  # æ¯ä¸ªé«˜æƒé‡æ ‡ç­¾æœ€å¤š3ç¯‡
                )
                recommendations.extend(first_tier)
                print(f"ğŸ” ç¬¬ä¸€å±‚åused_content_ids: {used_content_ids}")
                print(f"   âœ… ç¬¬ä¸€å±‚æ¨è: {len(first_tier)}ç¯‡")
            
            # ç¬¬äºŒå±‚ï¼šä¸­ç­‰æƒé‡æ ‡ç­¾åŒ¹é…ï¼ˆæƒé‡ 2.0-4.0ï¼‰
            if len(recommendations) < limit:
                medium_weight_tags = [tag for tag in adjusted_tags if 2.0 <= tag.weight < 4.0]
                if medium_weight_tags:
                    print(f"ğŸŸ¡ ç¬¬äºŒå±‚ï¼šä¸­æƒé‡æ ‡ç­¾ ({len(medium_weight_tags)}ä¸ª)")
                    
                    print(f"ğŸ” ç¬¬äºŒå±‚å‰used_content_ids: {used_content_ids}")
                    second_tier = await self._get_precise_content_by_tags(
                        medium_weight_tags,
                        used_content_ids,
                        max_per_tag=2  # æ¯ä¸ªä¸­æƒé‡æ ‡ç­¾æœ€å¤š2ç¯‡
                    )
                    recommendations.extend(second_tier)
                    print(f"ğŸ” ç¬¬äºŒå±‚åused_content_ids: {used_content_ids}")
                    print(f"   âœ… ç¬¬äºŒå±‚æ¨è: {len(second_tier)}ç¯‡")
            
            # ç¬¬ä¸‰å±‚ï¼šä½æƒé‡æ ‡ç­¾åŒ¹é…ï¼ˆæƒé‡ < 2.0ï¼‰
            if len(recommendations) < limit:
                low_weight_tags = [tag for tag in adjusted_tags if tag.weight < 2.0]
                if low_weight_tags:
                    print(f"ğŸ”µ ç¬¬ä¸‰å±‚ï¼šä½æƒé‡æ ‡ç­¾ ({len(low_weight_tags)}ä¸ª)")
                    
                    print(f"ğŸ” ç¬¬ä¸‰å±‚å‰used_content_ids: {used_content_ids}")
                    third_tier = await self._get_precise_content_by_tags(
                        low_weight_tags,
                        used_content_ids,
                        max_per_tag=1  # æ¯ä¸ªä½æƒé‡æ ‡ç­¾æœ€å¤š1ç¯‡
                    )
                    recommendations.extend(third_tier)
                    print(f"ğŸ” ç¬¬ä¸‰å±‚åused_content_ids: {used_content_ids}")
                    print(f"   âœ… ç¬¬ä¸‰å±‚æ¨è: {len(third_tier)}ç¯‡")
            
            # ç¬¬å››å±‚ï¼šå¦‚æœè¿˜ä¸å¤Ÿï¼Œè¡¥å……æœ€æ–°å†…å®¹
            if len(recommendations) < limit:
                print(f"ğŸ“° ç¬¬å››å±‚ï¼šè¡¥å……æœ€æ–°å†…å®¹")
                remaining_limit = limit - len(recommendations)
                latest_content = await self.content_service.get_content_list(
                    skip=0, 
                    limit=remaining_limit * 2  # å¤šå–ä¸€äº›ç”¨äºè¿‡æ»¤
                )
                
                # è¿‡æ»¤æ‰å·²æ¨èçš„å†…å®¹
                for content in latest_content:
                    if content.id not in used_content_ids and len(recommendations) < limit:
                        recommendations.append(content)
                        used_content_ids.add(content.id)
                
                print(f"   âœ… ç¬¬å››å±‚è¡¥å……: {len(recommendations) - len(recommendations)}ç¯‡")
            
            # åº”ç”¨åˆ†é¡µ
            if skip > 0:
                recommendations = recommendations[skip:]
            recommendations = recommendations[:limit]
            
            # ä¸ºæ¯ä¸ªæ¨èå†…å®¹è®¡ç®—æœ€ç»ˆç›¸å…³æ€§åˆ†æ•°
            for content in recommendations:
                content.relevance_score = await self.calculate_content_relevance_score_v2(
                    user_tags, content
                )
            
            # ğŸ¯ å…³é”®ä¿®æ”¹ï¼šæŒ‰ç›¸å…³æ€§åˆ†æ•°é‡æ–°æ’åºæ•´ä¸ªæ¨èåˆ—è¡¨
            recommendations.sort(key=lambda x: x.relevance_score or 0, reverse=True)
            
            print(f"ğŸ¯ æ™ºèƒ½æ¨èå®Œæˆ: è¿”å› {len(recommendations)} ç¯‡å†…å®¹")
            
            # è¾“å‡ºæ¨èå†…å®¹çš„æ ‡ç­¾åŒ¹é…æƒ…å†µ
            for i, content in enumerate(recommendations[:5]):  # åªæ˜¾ç¤ºå‰5ç¯‡
                content_tags = self._get_all_content_tags(content)
                matched_user_tags = [tag.name for tag in adjusted_tags if tag.name in content_tags]
                print(f"   ğŸ“„ {i+1}. {content.title[:50]}...")
                print(f"       ğŸ·ï¸ åŒ¹é…æ ‡ç­¾: {matched_user_tags}")
                print(f"       â­ ç›¸å…³æ€§: {content.relevance_score:.2f}")
                print(f"       ğŸ“… æ—¶é—´: {content.publish_time}")
            
            # ğŸ¯ æ¨èæœåŠ¡å±‚æœ€ç»ˆå»é‡ä¿éšœï¼ˆåœ¨æ’åºåï¼‰
            unique_recommendations = []
            seen_ids = set()
            
            print(f"ğŸ” æ¨èæœåŠ¡å±‚æœ€ç»ˆå»é‡: è¾“å…¥ {len(recommendations)} æ¡æ¨è")
            
            for i, content in enumerate(recommendations):
                content_id = content.id
                if content_id not in seen_ids:
                    unique_recommendations.append(content)
                    seen_ids.add(content_id)
                    print(f"   âœ… ä¿ç•™ç¬¬{i+1}æ¡: {content.title[:30]}... (ID: {content_id})")
                else:
                    print(f"   âŒ æ¨èæœåŠ¡å±‚å»é‡ï¼šè·³è¿‡ç¬¬{i+1}æ¡é‡å¤å†…å®¹: {content.title[:30]}... (ID: {content_id})")
            
            final_recommendations = unique_recommendations
            print(f"ğŸ¯ æ¨èæœåŠ¡å±‚å»é‡å®Œæˆ: {len(recommendations)} â†’ {len(final_recommendations)} æ¡å”¯ä¸€æ¨è")
            
            print(f"ğŸ¯ æ™ºèƒ½æ¨èå®Œæˆ: è¿”å› {len(final_recommendations)} ç¯‡å†…å®¹")
            
            # è¾“å‡ºæ¨èå†…å®¹çš„æ ‡ç­¾åŒ¹é…æƒ…å†µ
            for i, content in enumerate(final_recommendations[:3]):  # åªæ˜¾ç¤ºå‰3ç¯‡
                content_tags = self._get_all_content_tags(content)
                matched_user_tags = [tag.name for tag in adjusted_tags if tag.name in content_tags]
                print(f"   ğŸ“„ {i+1}. {content.title[:50]}...")
                print(f"       ğŸ·ï¸ åŒ¹é…æ ‡ç­¾: {matched_user_tags}")
                print(f"       â­ ç›¸å…³æ€§: {content.relevance_score:.2f}")
                print(f"       ğŸ“… æ—¶é—´: {content.publish_time}")
            
            return final_recommendations
            
        except Exception as e:
            print(f"âŒ æ™ºèƒ½æ¨èå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            # å›é€€åˆ°æ™®é€šæ¨è
            return await self.get_user_recommendations(user_id, skip, limit)

    async def _get_precise_content_by_tags(
        self,
        tags: List[UserTag],
        used_content_ids: set,
        max_per_tag: int = 2
    ) -> List[Content]:
        """
        ğŸ¯ æ ¹æ®æ ‡ç­¾ç²¾å‡†è·å–å†…å®¹
        
        Args:
            tags: ç”¨æˆ·æ ‡ç­¾åˆ—è¡¨
            used_content_ids: å·²ä½¿ç”¨çš„å†…å®¹IDé›†åˆ
            max_per_tag: æ¯ä¸ªæ ‡ç­¾æœ€å¤šè¿”å›å¤šå°‘ç¯‡å†…å®¹
            
        Returns:
            List[Content]: åŒ¹é…çš„å†…å®¹åˆ—è¡¨ï¼ˆæŒ‰ç›¸å…³æ€§åˆ†æ•°æ’åºï¼‰
        """
        content_list = []
        
        for tag in tags:
            print(f"ğŸ” æœç´¢æ ‡ç­¾: {tag.name} (æƒé‡: {tag.weight})")
            
            # æ ¹æ®æ ‡ç­¾æœç´¢å†…å®¹
            tag_content = await self.content_service.get_content_by_user_tags(
                user_tags=[tag.name],
                skip=0,
                limit=max_per_tag * 3  # å¤šå–ä¸€äº›ç”¨äºè¿‡æ»¤
            )
            
            # è¿‡æ»¤å·²ä½¿ç”¨çš„å†…å®¹
            filtered_content = []
            for content in tag_content:
                if content.id not in used_content_ids:
                    filtered_content.append(content)
                    used_content_ids.add(content.id)
            
            # åªå–å‰ max_per_tag ç¯‡
            selected_content = filtered_content[:max_per_tag]
            content_list.extend(selected_content)
            
            print(f"   âœ… æ‰¾åˆ° {len(selected_content)} ç¯‡å†…å®¹ (æ€»å…± {len(tag_content)} ç¯‡)")
            
            # æ˜¾ç¤ºåŒ¹é…çš„å†…å®¹ä¿¡æ¯
            for content in selected_content:
                print(f"      ğŸ“„ {content.title[:30]}... ({content.publish_time})")
        
        return content_list

    def _get_all_content_tags(self, content: Content) -> List[str]:
        """è·å–å†…å®¹çš„æ‰€æœ‰æ ‡ç­¾"""
        all_tags = []
        
        # æ”¶é›†æ‰€æœ‰æ ‡ç­¾å­—æ®µ
        tag_fields = [
            'basic_info_tags', 'region_tags', 'energy_type_tags',
            'business_field_tags', 'beneficiary_tags', 
            'policy_measure_tags', 'importance_tags'
        ]
        
        for field in tag_fields:
            if hasattr(content, field):
                field_tags = getattr(content, field, [])
                if field_tags:
                    all_tags.extend(field_tags)
        
        # å»é‡
        return list(set(all_tags))

    async def get_smart_recommendations_by_type(
        self,
        user_id: str,
        content_types: List[str],
        basic_info_tags: List[str],
        skip: int = 0,
        limit: int = 10
    ) -> List[Content]:
        """
        ğŸ¯ æŒ‰å†…å®¹ç±»å‹çš„æ™ºèƒ½æ¨èï¼šæƒé‡ä¼˜å…ˆ + æ—¶é—´è°ƒèŠ‚
        
        Args:
            user_id: ç”¨æˆ·ID
            content_types: å†…å®¹ç±»å‹åˆ—è¡¨ ['news', 'policy', 'announcement', 'price']
            basic_info_tags: åŸºç¡€ä¿¡æ¯æ ‡ç­¾åˆ—è¡¨ ['è¡Œä¸šèµ„è®¯', 'æ”¿ç­–æ³•è§„', 'äº¤æ˜“å…¬å‘Š', 'è°ƒä»·å…¬å‘Š'] 
            skip: è·³è¿‡æ•°é‡
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            List[Content]: æŒ‰ç±»å‹ç­›é€‰çš„æ™ºèƒ½æ¨èå†…å®¹
        """
        try:
            print(f"ğŸ¯ æŒ‰ç±»å‹æ™ºèƒ½æ¨è - ç”¨æˆ·: {user_id}, ç±»å‹: {content_types}, æ ‡ç­¾: {basic_info_tags}")
            
            # è·å–ç”¨æˆ·æ ‡ç­¾
            user_tags = await self.user_service.get_user_tags(user_id)
            
            if not user_tags or not user_tags.tags:
                try:
                    user_tags = await self.user_service.ensure_user_has_tags(user_id)
                except:
                    print(f"âŒ ç”¨æˆ· {user_id} æ— æ ‡ç­¾ï¼Œè¿”å›ç©ºå†…å®¹")
                    return []
            
            print(f"ğŸ·ï¸ ç”¨æˆ·æ ‡ç­¾æ•°é‡: {len(user_tags.tags)}")
            
            # æ ¹æ®ç”¨æˆ·è¡Œä¸ºè°ƒæ•´æ ‡ç­¾æƒé‡
            adjusted_tags = await self.adjust_tag_weights_by_behavior(user_id, user_tags.tags)
            
            # æŒ‰æ ‡ç­¾æƒé‡æ’åºï¼Œæƒé‡é«˜çš„ä¼˜å…ˆ
            adjusted_tags.sort(key=lambda x: x.weight, reverse=True)
            
            # ğŸ”¥ æ„å»ºç±»å‹ç­›é€‰æŸ¥è¯¢æ¡ä»¶
            type_filter = {
                "$or": [
                    {"type": {"$in": content_types}},
                    {"basic_info_tags": {"$in": basic_info_tags}}
                ]
            }
            
            print(f"ğŸ” ç±»å‹ç­›é€‰æ¡ä»¶: {type_filter}")
            
            # ğŸ”¥ åˆ†å±‚æ¨èç­–ç•¥ï¼ˆä»…åœ¨æŒ‡å®šç±»å‹å†…ï¼‰
            recommendations = []
            used_content_ids = set()
            
            print(f"ğŸ¯ å¼€å§‹åˆ†å±‚æ¨èï¼Œåˆå§‹used_content_ids: {len(used_content_ids)}")
            
            # ç¬¬ä¸€å±‚ï¼šæœ€é«˜æƒé‡æ ‡ç­¾ç²¾å‡†åŒ¹é…ï¼ˆæƒé‡ >= 4.0ï¼‰
            high_weight_tags = [tag for tag in adjusted_tags if tag.weight >= 4.0]
            if high_weight_tags:
                print(f"ğŸ”¥ ç¬¬ä¸€å±‚ï¼šé«˜æƒé‡æ ‡ç­¾ ({len(high_weight_tags)}ä¸ª)")
                for tag in high_weight_tags:
                    print(f"   ğŸ·ï¸ {tag.name} (æƒé‡: {tag.weight})")
                
                print(f"ğŸ” ç¬¬ä¸€å±‚å‰used_content_ids: {used_content_ids}")
                first_tier = await self._get_precise_content_by_tags_and_type(
                    high_weight_tags,
                    used_content_ids,
                    type_filter,
                    max_per_tag=3
                )
                recommendations.extend(first_tier)
                print(f"ğŸ” ç¬¬ä¸€å±‚åused_content_ids: {used_content_ids}")
                print(f"   âœ… ç¬¬ä¸€å±‚æ¨è: {len(first_tier)}ç¯‡")
            
            # ç¬¬äºŒå±‚ï¼šä¸­ç­‰æƒé‡æ ‡ç­¾åŒ¹é…ï¼ˆæƒé‡ 2.0-4.0ï¼‰
            if len(recommendations) < limit:
                medium_weight_tags = [tag for tag in adjusted_tags if 2.0 <= tag.weight < 4.0]
                if medium_weight_tags:
                    print(f"ğŸŸ¡ ç¬¬äºŒå±‚ï¼šä¸­æƒé‡æ ‡ç­¾ ({len(medium_weight_tags)}ä¸ª)")
                    
                    print(f"ğŸ” ç¬¬äºŒå±‚å‰used_content_ids: {used_content_ids}")
                    second_tier = await self._get_precise_content_by_tags_and_type(
                        medium_weight_tags,
                        used_content_ids,
                        type_filter,
                        max_per_tag=2
                    )
                    recommendations.extend(second_tier)
                    print(f"ğŸ” ç¬¬äºŒå±‚åused_content_ids: {used_content_ids}")
                    print(f"   âœ… ç¬¬äºŒå±‚æ¨è: {len(second_tier)}ç¯‡")
            
            # ç¬¬ä¸‰å±‚ï¼šä½æƒé‡æ ‡ç­¾åŒ¹é…ï¼ˆæƒé‡ < 2.0ï¼‰
            if len(recommendations) < limit:
                low_weight_tags = [tag for tag in adjusted_tags if tag.weight < 2.0]
                if low_weight_tags:
                    print(f"ğŸ”µ ç¬¬ä¸‰å±‚ï¼šä½æƒé‡æ ‡ç­¾ ({len(low_weight_tags)}ä¸ª)")
                    
                    print(f"ğŸ” ç¬¬ä¸‰å±‚å‰used_content_ids: {used_content_ids}")
                    third_tier = await self._get_precise_content_by_tags_and_type(
                        low_weight_tags,
                        used_content_ids,
                        type_filter,
                        max_per_tag=1
                    )
                    recommendations.extend(third_tier)
                    print(f"ğŸ” ç¬¬ä¸‰å±‚åused_content_ids: {used_content_ids}")
                    print(f"   âœ… ç¬¬ä¸‰å±‚æ¨è: {len(third_tier)}ç¯‡")
            
            # ç¬¬å››å±‚ï¼šå¦‚æœè¿˜ä¸å¤Ÿï¼Œè¡¥å……è¯¥ç±»å‹çš„æœ€æ–°å†…å®¹
            if len(recommendations) < limit:
                print(f"ğŸ“° ç¬¬å››å±‚ï¼šè¡¥å……è¯¥ç±»å‹æœ€æ–°å†…å®¹")
                remaining_limit = limit - len(recommendations)
                
                # æŸ¥è¯¢è¯¥ç±»å‹çš„æœ€æ–°å†…å®¹
                latest_content_cursor = self.content_service.collection.find(type_filter).sort("publish_time", -1)
                latest_content_docs = await latest_content_cursor.to_list(length=remaining_limit * 2)
                
                # ğŸ”¥ ä¿®å¤é‡å¤é—®é¢˜ï¼šæ£€æŸ¥used_content_ids
                added_count = 0
                for doc in latest_content_docs:
                    content_id = str(doc['_id'])
                    
                    # ç¡®ä¿å†…å®¹ä¸é‡å¤ä¸”æ•°é‡ä¸è¶…é™
                    if content_id not in used_content_ids and len(recommendations) < limit:
                        doc['id'] = content_id
                        content = Content(**doc)
                        recommendations.append(content)
                        used_content_ids.add(content_id)
                        added_count += 1
                        
                        print(f"      âœ… è¡¥å……å†…å®¹: {content.title[:30]}... (ID: {content_id})")
                    else:
                        if content_id in used_content_ids:
                            print(f"      âš ï¸ å†…å®¹å·²å­˜åœ¨ï¼Œè·³è¿‡: {doc.get('title', 'Unknown')[:30]}... (ID: {content_id})")
                
                print(f"   âœ… ç¬¬å››å±‚è¡¥å……: {added_count}ç¯‡æ–°å†…å®¹")
            
            # åº”ç”¨åˆ†é¡µ
            if skip > 0:
                recommendations = recommendations[skip:]
            recommendations = recommendations[:limit]
            
            # ä¸ºæ¯ä¸ªæ¨èå†…å®¹è®¡ç®—æœ€ç»ˆç›¸å…³æ€§åˆ†æ•°
            for content in recommendations:
                content.relevance_score = await self.calculate_content_relevance_score_v2(
                    user_tags, content
                )
            
            # ğŸ¯ å…³é”®ï¼šæŒ‰ç›¸å…³æ€§åˆ†æ•°é‡æ–°æ’åºæ•´ä¸ªæ¨èåˆ—è¡¨
            recommendations.sort(key=lambda x: x.relevance_score or 0, reverse=True)
            
            # ğŸ”¥ æ¨èæœåŠ¡å±‚æœ€ç»ˆå»é‡ä¿éšœï¼ˆåœ¨æ’åºåï¼‰
            unique_recommendations = []
            seen_ids = set()
            
            print(f"ğŸ” æ¨èæœåŠ¡å±‚æœ€ç»ˆå»é‡: è¾“å…¥ {len(recommendations)} æ¡æ¨è")
            
            for i, content in enumerate(recommendations):
                content_id = content.id
                if content_id not in seen_ids:
                    unique_recommendations.append(content)
                    seen_ids.add(content_id)
                    print(f"   âœ… ä¿ç•™ç¬¬{i+1}æ¡: {content.title[:30]}... (ID: {content_id})")
                else:
                    print(f"   âŒ æ¨èæœåŠ¡å±‚å»é‡ï¼šè·³è¿‡ç¬¬{i+1}æ¡é‡å¤å†…å®¹: {content.title[:30]}... (ID: {content_id})")
            
            final_recommendations = unique_recommendations
            print(f"ğŸ¯ æ¨èæœåŠ¡å±‚å»é‡å®Œæˆ: {len(recommendations)} â†’ {len(final_recommendations)} æ¡å”¯ä¸€æ¨è")
            
            print(f"ğŸ¯ æŒ‰ç±»å‹æ™ºèƒ½æ¨èå®Œæˆ: è¿”å› {len(final_recommendations)} ç¯‡ {content_types} ç±»å‹å†…å®¹")
            
            # è¾“å‡ºæ¨èå†…å®¹çš„æ ‡ç­¾åŒ¹é…æƒ…å†µ
            for i, content in enumerate(final_recommendations[:3]):  # åªæ˜¾ç¤ºå‰3ç¯‡
                content_tags = self._get_all_content_tags(content)
                matched_user_tags = [tag.name for tag in adjusted_tags if tag.name in content_tags]
                print(f"   ğŸ“„ {i+1}. {content.title[:50]}...")
                print(f"       ğŸ·ï¸ åŒ¹é…æ ‡ç­¾: {matched_user_tags}")
                print(f"       â­ ç›¸å…³æ€§: {content.relevance_score:.2f}")
                print(f"       ğŸ“… æ—¶é—´: {content.publish_time}")
                print(f"       ğŸ·ï¸ ç±»å‹: {content.type}")
            
            return final_recommendations
            
        except Exception as e:
            print(f"âŒ æŒ‰ç±»å‹æ™ºèƒ½æ¨èå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return []

    async def _get_precise_content_by_tags_and_type(
        self,
        tags: List[UserTag],
        used_content_ids: set,
        type_filter: dict,
        max_per_tag: int = 2
    ) -> List[Content]:
        """
        ğŸ¯ æ ¹æ®æ ‡ç­¾å’Œç±»å‹ç²¾å‡†è·å–å†…å®¹
        
        Args:
            tags: ç”¨æˆ·æ ‡ç­¾åˆ—è¡¨
            used_content_ids: å·²ä½¿ç”¨çš„å†…å®¹IDé›†åˆ
            type_filter: ç±»å‹ç­›é€‰æ¡ä»¶
            max_per_tag: æ¯ä¸ªæ ‡ç­¾æœ€å¤šè¿”å›å¤šå°‘ç¯‡å†…å®¹
            
        Returns:
            List[Content]: åŒ¹é…çš„å†…å®¹åˆ—è¡¨
        """
        content_list = []
        
        for tag in tags:
            print(f"ğŸ” æœç´¢æ ‡ç­¾: {tag.name} (æƒé‡: {tag.weight}) åœ¨æŒ‡å®šç±»å‹ä¸­")
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶ï¼šæ ‡ç­¾åŒ¹é… + ç±»å‹ç­›é€‰
            query = {
                "$and": [
                    type_filter,  # ç±»å‹ç­›é€‰
                    {
                        "$or": [
                            {"basic_info_tags": tag.name},
                            {"region_tags": tag.name},
                            {"energy_type_tags": tag.name},
                            {"business_field_tags": tag.name},
                            {"beneficiary_tags": tag.name},
                            {"policy_measure_tags": tag.name},
                            {"importance_tags": tag.name}
                        ]
                    }
                ]
            }
            
            # æŸ¥è¯¢åŒ¹é…çš„å†…å®¹
            content_cursor = self.content_service.collection.find(query).sort("publish_time", -1)
            content_docs = await content_cursor.to_list(length=max_per_tag * 3)
            
            # ğŸ”¥ ç®€åŒ–å»é‡é€»è¾‘ï¼šåªæ£€æŸ¥used_content_idsï¼Œç¡®ä¿å†…å®¹ä¸é‡å¤
            tag_content_count = 0  # è¯¥æ ‡ç­¾å·²æ·»åŠ çš„å†…å®¹æ•°é‡
            
            for doc in content_docs:
                content_id = str(doc['_id'])
                
                # ğŸ¯ å…³é”®ä¿®å¤ï¼šåªæ£€æŸ¥used_content_idsï¼Œé¿å…é‡å¤é€»è¾‘
                if content_id not in used_content_ids:
                    doc['id'] = content_id
                    content = Content(**doc)
                    content_list.append(content)
                    used_content_ids.add(content_id)
                    tag_content_count += 1
                    
                    print(f"      âœ… æ·»åŠ å†…å®¹: {content.title[:30]}... (ID: {content_id})")
                    
                    # è¯¥æ ‡ç­¾è¾¾åˆ°æœ€å¤§æ•°é‡é™åˆ¶ï¼Œåœæ­¢æ·»åŠ 
                    if tag_content_count >= max_per_tag:
                        break
                else:
                    print(f"      âš ï¸ å†…å®¹å·²å­˜åœ¨ï¼Œè·³è¿‡: {doc.get('title', 'Unknown')[:30]}... (ID: {content_id})")
            
            print(f"   âœ… æ ‡ç­¾ {tag.name} æ‰¾åˆ° {tag_content_count} ç¯‡æ–°å†…å®¹")
        
        print(f"ğŸ¯ æŒ‰æ ‡ç­¾å’Œç±»å‹æœç´¢å®Œæˆï¼Œæ€»å…±æ‰¾åˆ° {len(content_list)} ç¯‡å†…å®¹")
        return content_list 