from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta
from app.models.user import UserRole, AdminPermission, User, UserProfile
from app.models.content import Content, ContentCreateRequest, ContentUpdateRequest, JsonArticle, CONTENT_TYPE_MAP
from app.core.security import verify_password, create_access_token, get_password_hash
from app.core.database import get_database
from app.utils.region_mapper import RegionMapper
from app.services.user_service import UserService
from app.utils.tag_processor import TagProcessor
from app.core.config import settings
import logging
import json
import ast
from bson import ObjectId

logger = logging.getLogger(__name__)

# ç¡¬ç¼–ç çš„ç®¡ç†å‘˜è´¦æˆ·é…ç½®
BUILTIN_ADMIN_ACCOUNTS = {
    "admin": {
        "username": "admin",
        "email": "admin@energy-system.com",
        "password_hash": get_password_hash("admin123456"),  # é»˜è®¤å¯†ç 
        "role": UserRole.ADMIN,
        "is_active": True,
        "register_city": "åŒ—äº¬"
    },
    "superadmin": {
        "username": "superadmin", 
        "email": "superadmin@energy-system.com",
        "password_hash": get_password_hash("super123456"),  # è¶…çº§ç®¡ç†å‘˜å¯†ç 
        "role": UserRole.ADMIN,
        "is_active": True,
        "register_city": "åŒ—äº¬"
    }
}

class AdminService:
    def __init__(self, db):
        self.db = db
        self.users_collection = db.users
        self.content_collection = db.content
        
    async def authenticate_admin(self, username: str, password: str) -> Optional[User]:
        """ç®¡ç†å‘˜è®¤è¯ - ä½¿ç”¨ç¡¬ç¼–ç è´¦æˆ·"""
        try:
            logger.info(f"ğŸ” å°è¯•ç®¡ç†å‘˜è®¤è¯: {username}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å†…ç½®ç®¡ç†å‘˜è´¦æˆ·
            admin_account = None
            
            # æ”¯æŒç”¨æˆ·åæˆ–é‚®ç®±ç™»å½•
            for account_key, account_info in BUILTIN_ADMIN_ACCOUNTS.items():
                if (username == account_info["username"] or 
                    username == account_info["email"]):
                    admin_account = account_info
                    break
            
            if not admin_account:
                logger.warning(f"âŒ ç®¡ç†å‘˜è´¦æˆ·ä¸å­˜åœ¨: {username}")
                return None
            
            # éªŒè¯å¯†ç 
            if not verify_password(password, admin_account["password_hash"]):
                logger.warning(f"âŒ ç®¡ç†å‘˜å¯†ç é”™è¯¯: {username}")
                return None
            
            # åˆ›å»ºç®¡ç†å‘˜ç”¨æˆ·å¯¹è±¡
            admin_user = User(
                id=f"builtin_admin_{admin_account['username']}",  # ä½¿ç”¨ç‰¹æ®ŠIDæ ‡è¯†å†…ç½®ç®¡ç†å‘˜
                email=admin_account["email"],
                username=admin_account["username"],
                role=admin_account["role"],
                is_active=admin_account["is_active"],
                created_at=datetime.utcnow().isoformat(),
                has_initial_tags=True,  # ç®¡ç†å‘˜é»˜è®¤å·²é…ç½®æ ‡ç­¾
                register_city=admin_account["register_city"]
            )
            
            logger.info(f"âœ… ç®¡ç†å‘˜è®¤è¯æˆåŠŸ: {username}")
            return admin_user
            
        except Exception as e:
            logger.error(f"âŒ ç®¡ç†å‘˜è®¤è¯å¼‚å¸¸: {str(e)}")
            return None
    
    def get_admin_permissions(self, user_role: UserRole) -> List[str]:
        """è·å–ç®¡ç†å‘˜æƒé™åˆ—è¡¨"""
        if user_role == UserRole.ADMIN:
            return [
                AdminPermission.MANAGE_ARTICLES,
                AdminPermission.MANAGE_USERS,
                AdminPermission.MANAGE_TAGS,
                AdminPermission.VIEW_ANALYTICS,
                AdminPermission.SYSTEM_CONFIG
            ]
        return []
    
    async def create_article(self, article_data: ContentCreateRequest, admin_id: str) -> Content:
        """åˆ›å»ºæ–‡ç« """
        try:
            # åˆ›å»ºæ–‡ç« å¯¹è±¡
            article_dict = article_data.dict()
            article_dict["id"] = str(ObjectId())
            article_dict["created_at"] = datetime.utcnow()
            article_dict["updated_at"] = datetime.utcnow()
            
            if not article_dict.get("publish_time"):
                article_dict["publish_time"] = datetime.utcnow()
            
            # æ’å…¥æ•°æ®åº“
            result = await self.content_collection.insert_one(article_dict)
            
            # è¿”å›åˆ›å»ºçš„æ–‡ç« 
            article_dict["_id"] = str(result.inserted_id)
            content = Content(**article_dict)
            
            logger.info(f"ç®¡ç†å‘˜ {admin_id} åˆ›å»ºæ–‡ç« æˆåŠŸ: {content.title}")
            return content
            
        except Exception as e:
            logger.error(f"åˆ›å»ºæ–‡ç« å¤±è´¥: {str(e)}")
            raise Exception(f"åˆ›å»ºæ–‡ç« å¤±è´¥: {str(e)}")
    
    async def update_article(self, article_id: str, update_data: ContentUpdateRequest, admin_id: str) -> Content:
        """æ›´æ–°æ–‡ç« """
        try:
            # æ£€æŸ¥æ–‡ç« æ˜¯å¦å­˜åœ¨
            existing_article = await self.content_collection.find_one({"_id": ObjectId(article_id)})
            if not existing_article:
                raise Exception("æ–‡ç« ä¸å­˜åœ¨")
            
            # å‡†å¤‡æ›´æ–°æ•°æ®
            update_dict = {}
            for field, value in update_data.dict(exclude_unset=True).items():
                if value is not None:
                    update_dict[field] = value
            
            update_dict["updated_at"] = datetime.utcnow()
            
            # æ›´æ–°æ•°æ®åº“
            await self.content_collection.update_one(
                {"_id": ObjectId(article_id)},
                {"$set": update_dict}
            )
            
            # è·å–æ›´æ–°åçš„æ–‡ç« 
            updated_article = await self.content_collection.find_one({"_id": ObjectId(article_id)})
            updated_article["id"] = str(updated_article["_id"])
            content = Content(**updated_article)
            
            logger.info(f"ç®¡ç†å‘˜ {admin_id} æ›´æ–°æ–‡ç« æˆåŠŸ: {content.title}")
            return content
            
        except Exception as e:
            logger.error(f"æ›´æ–°æ–‡ç« å¤±è´¥: {str(e)}")
            raise Exception(f"æ›´æ–°æ–‡ç« å¤±è´¥: {str(e)}")
    
    async def delete_article(self, article_id: str, admin_id: str) -> bool:
        """åˆ é™¤æ–‡ç« """
        try:
            # æ£€æŸ¥æ–‡ç« æ˜¯å¦å­˜åœ¨
            existing_article = await self.content_collection.find_one({"_id": ObjectId(article_id)})
            if not existing_article:
                raise Exception("æ–‡ç« ä¸å­˜åœ¨")
            
            # åˆ é™¤æ–‡ç« 
            result = await self.content_collection.delete_one({"_id": ObjectId(article_id)})
            
            if result.deleted_count > 0:
                logger.info(f"ç®¡ç†å‘˜ {admin_id} åˆ é™¤æ–‡ç« æˆåŠŸ: {existing_article.get('title', 'Unknown')}")
                return True
            else:
                return False
                
        except Exception as e:
            logger.error(f"åˆ é™¤æ–‡ç« å¤±è´¥: {str(e)}")
            raise Exception(f"åˆ é™¤æ–‡ç« å¤±è´¥: {str(e)}")
    
    def parse_json_tags(self, tag_string: Optional[str]) -> List[str]:
        """è§£æJSONå­—ç¬¦ä¸²æ ¼å¼çš„æ ‡ç­¾ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„TagProcessorï¼‰"""
        return TagProcessor.safe_parse_tags(tag_string)
    
    def convert_json_article_to_content(self, json_article: JsonArticle) -> Dict[str, Any]:
        """å°†JSONæ ¼å¼çš„æ–‡ç« è½¬æ¢ä¸ºContentæ ¼å¼"""
        try:
            # å¤„ç†å‘å¸ƒæ—¶é—´
            publish_time = datetime.utcnow()
            try:
                if json_article.å‘å¸ƒæ—¶é—´:
                    publish_time = datetime.strptime(json_article.å‘å¸ƒæ—¶é—´, "%Y-%m-%d")
            except:
                try:
                    publish_time = datetime.strptime(json_article.å‘å¸ƒæ—¥æœŸ, "%Y-%m-%d")
                except:
                    pass
            
            # ğŸ”¥ è§£æåŸºç¡€ä¿¡æ¯æ ‡ç­¾ï¼ŒåŸºäºæ­¤ç¡®å®šå†…å®¹ç±»å‹
            basic_info_tags = self.parse_json_tags(json_article.åŸºç¡€ä¿¡æ¯æ ‡ç­¾)
            
            # ğŸ”¥ åŸºäºåŸºç¡€ä¿¡æ¯æ ‡ç­¾ç¡®å®šå†…å®¹ç±»å‹
            content_type = "news"  # é»˜è®¤ä¸ºè¡Œä¸šèµ„è®¯
            if basic_info_tags:
                # æŒ‰ä¼˜å…ˆçº§åŒ¹é…å†…å®¹ç±»å‹
                if "æ”¿ç­–æ³•è§„" in basic_info_tags:
                    content_type = "policy"
                elif "è°ƒä»·å…¬å‘Š" in basic_info_tags:
                    content_type = "price"
                elif "äº¤æ˜“å…¬å‘Š" in basic_info_tags:
                    content_type = "announcement"
                elif "è¡Œä¸šèµ„è®¯" in basic_info_tags:
                    content_type = "news"
            
            # è§£æå…¶ä»–æ ‡ç­¾
            region_tags = self.parse_json_tags(json_article.åœ°åŸŸæ ‡ç­¾)
            energy_type_tags = json_article.èƒ½æºå“ç§æ ‡ç­¾ or []
            business_field_tags = self.parse_json_tags(json_article.ä¸šåŠ¡é¢†åŸŸæ ‡ç­¾)
            beneficiary_tags = self.parse_json_tags(json_article.å—ç›Šä¸»ä½“æ ‡ç­¾)
            policy_measure_tags = self.parse_json_tags(json_article.å…³é”®æªæ–½æ ‡ç­¾)
            importance_tags = self.parse_json_tags(json_article.é‡è¦æ€§æ ‡ç­¾)
            
            # æ·»åŠ è§„èŒƒåŒ–åœ°åŸŸæ ‡ç­¾
            if json_article.è§„èŒƒåŒ–åœ°åŸŸæ ‡ç­¾:
                region_tags.extend(json_article.è§„èŒƒåŒ–åœ°åŸŸæ ‡ç­¾)
            
            # å»é‡
            region_tags = list(set(region_tags))
            
            content_dict = {
                "title": json_article.æ ‡é¢˜,
                "content": json_article.æ–‡ç« å†…å®¹,
                "type": content_type,  # ğŸ”¥ åŸºäºbasic_info_tagsç”Ÿæˆ
                "source": json_article.æ¥æºæœºæ„,
                "publish_time": publish_time,
                "link": json_article.é“¾æ¥,
                "basic_info_tags": basic_info_tags,
                "region_tags": region_tags,
                "energy_type_tags": energy_type_tags,
                "business_field_tags": business_field_tags,
                "beneficiary_tags": beneficiary_tags,
                "policy_measure_tags": policy_measure_tags,
                "importance_tags": importance_tags,
                "created_at": datetime.utcnow(),
                "updated_at": datetime.utcnow(),
                "view_count": 0
            }
            
            return content_dict
            
        except Exception as e:
            logger.error(f"è½¬æ¢JSONæ–‡ç« å¤±è´¥: {str(e)}")
            raise Exception(f"è½¬æ¢JSONæ–‡ç« å¤±è´¥: {str(e)}")
    
    async def batch_import_articles(self, articles: List[JsonArticle], admin_id: str, 
                                  auto_parse_tags: bool = True, overwrite_existing: bool = False) -> Dict[str, Any]:
        """æ‰¹é‡å¯¼å…¥æ–‡ç« """
        try:
            total_articles = len(articles)
            imported_count = 0
            updated_count = 0
            failed_count = 0
            failed_articles = []
            
            for i, json_article in enumerate(articles):
                try:
                    # è½¬æ¢ä¸ºContentæ ¼å¼
                    content_dict = self.convert_json_article_to_content(json_article)
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæ ‡é¢˜çš„æ–‡ç« 
                    existing_article = await self.content_collection.find_one({
                        "title": content_dict["title"]
                    })
                    
                    if existing_article:
                        if overwrite_existing:
                            # æ›´æ–°ç°æœ‰æ–‡ç« 
                            content_dict["updated_at"] = datetime.utcnow()
                            await self.content_collection.update_one(
                                {"_id": existing_article["_id"]},
                                {"$set": content_dict}
                            )
                            updated_count += 1
                            logger.info(f"æ›´æ–°æ–‡ç« : {content_dict['title']}")
                        else:
                            logger.info(f"è·³è¿‡å·²å­˜åœ¨çš„æ–‡ç« : {content_dict['title']}")
                            continue
                    else:
                        # æ’å…¥æ–°æ–‡ç« 
                        content_dict["_id"] = ObjectId()
                        await self.content_collection.insert_one(content_dict)
                        imported_count += 1
                        logger.info(f"å¯¼å…¥æ–°æ–‡ç« : {content_dict['title']}")
                        
                except Exception as e:
                    failed_count += 1
                    failed_articles.append({
                        "index": i,
                        "title": getattr(json_article, "æ ‡é¢˜", "Unknown"),
                        "error": str(e)
                    })
                    logger.error(f"å¯¼å…¥æ–‡ç« å¤±è´¥ (ç´¢å¼• {i}): {str(e)}")
            
            result = {
                "success": True,
                "total_articles": total_articles,
                "imported_count": imported_count,
                "updated_count": updated_count,
                "failed_count": failed_count,
                "failed_articles": failed_articles,
                "message": f"æ‰¹é‡å¯¼å…¥å®Œæˆ: æ–°å¢ {imported_count} ç¯‡ï¼Œæ›´æ–° {updated_count} ç¯‡ï¼Œå¤±è´¥ {failed_count} ç¯‡"
            }
            
            logger.info(f"ç®¡ç†å‘˜ {admin_id} æ‰¹é‡å¯¼å…¥æ–‡ç« å®Œæˆ: {result['message']}")
            return result
            
        except Exception as e:
            logger.error(f"æ‰¹é‡å¯¼å…¥æ–‡ç« å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "total_articles": len(articles),
                "imported_count": 0,
                "updated_count": 0,
                "failed_count": len(articles),
                "failed_articles": [],
                "message": f"æ‰¹é‡å¯¼å…¥å¤±è´¥: {str(e)}"
            }
    
    async def get_articles_for_management(self, page: int = 1, page_size: int = 20, 
                                        content_type: Optional[str] = None,
                                        energy_type: Optional[str] = None,
                                        search_keyword: Optional[str] = None,
                                        tag_search: Optional[str] = None) -> Dict[str, Any]:
        """è·å–æ–‡ç« ç®¡ç†åˆ—è¡¨"""
        try:
            skip = (page - 1) * page_size
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query = {}
            
            # ğŸ”¥ æ–‡ç« ç±»å‹ç­›é€‰ - ç»Ÿä¸€ä½¿ç”¨typeå­—æ®µ
            if content_type:
                query["type"] = content_type
            
            # èƒ½æºç±»å‹ç­›é€‰
            if energy_type:
                query["energy_type_tags"] = {"$in": [energy_type]}
            
            # å…³é”®è¯æœç´¢
            if search_keyword:
                search_conditions = [
                    {"æ ‡é¢˜": {"$regex": search_keyword, "$options": "i"}},
                    {"æ–‡ç« å†…å®¹": {"$regex": search_keyword, "$options": "i"}},
                    {"title": {"$regex": search_keyword, "$options": "i"}},
                    {"content": {"$regex": search_keyword, "$options": "i"}}
                ]
                
                if "$or" in query:
                    # å¦‚æœå·²ç»æœ‰$oræ¡ä»¶ï¼Œéœ€è¦åˆå¹¶
                    query = {"$and": [query, {"$or": search_conditions}]}
                else:
                    query["$or"] = search_conditions
            
            # æ ‡ç­¾æœç´¢
            if tag_search:
                tag_conditions = [
                    {"basic_info_tags": {"$regex": tag_search, "$options": "i"}},
                    {"region_tags": {"$regex": tag_search, "$options": "i"}},
                    {"energy_type_tags": {"$regex": tag_search, "$options": "i"}},
                    {"business_field_tags": {"$regex": tag_search, "$options": "i"}},
                    {"beneficiary_tags": {"$regex": tag_search, "$options": "i"}},
                    {"policy_measure_tags": {"$regex": tag_search, "$options": "i"}},
                    {"importance_tags": {"$regex": tag_search, "$options": "i"}}
                ]
                
                if "$and" in query:
                    # å¦‚æœå·²ç»æœ‰$andæ¡ä»¶ï¼Œæ·»åŠ åˆ°å…¶ä¸­
                    query["$and"].append({"$or": tag_conditions})
                elif "$or" in query:
                    # å¦‚æœæœ‰$oræ¡ä»¶ï¼Œéœ€è¦ç”¨$andåŒ…è£…
                    query = {"$and": [query, {"$or": tag_conditions}]}
                else:
                    query["$or"] = tag_conditions
            
            logger.info(f"ğŸ” MongoDBæŸ¥è¯¢æ¡ä»¶: {query}")
            
            # è·å–æ€»æ•°
            total_count = await self.content_collection.count_documents(query)
            logger.info(f"ğŸ“Š æŸ¥è¯¢ç»“æœæ€»æ•°: {total_count}")
            
            # è·å–æ–‡ç« åˆ—è¡¨
            cursor = self.content_collection.find(query).sort("å¯¼å…¥æ—¶é—´", -1).skip(skip).limit(page_size)
            articles = []
            
            async for doc in cursor:
                try:
                    # ä¸­æ–‡å­—æ®µååˆ°è‹±æ–‡å­—æ®µåçš„æ˜ å°„
                    mapped_doc = {
                        "id": str(doc["_id"]),
                        "title": doc.get("æ ‡é¢˜") or doc.get("title", "æ— æ ‡é¢˜"),
                        "content": doc.get("æ–‡ç« å†…å®¹") or doc.get("content", "æ— å†…å®¹"),
                        "source": doc.get("æ¥æºæœºæ„") or doc.get("source", "æœªçŸ¥æ¥æº"),
                        "link": doc.get("é“¾æ¥") or doc.get("link", ""),
                        "publish_time": doc.get("å‘å¸ƒæ—¶é—´") or doc.get("publish_time", datetime.utcnow()),
                        
                        # ğŸ”¥ typeå­—æ®µ - ä¼˜å…ˆä½¿ç”¨å·²æœ‰çš„typeå­—æ®µ
                        "type": doc.get("type", "news"),
                        
                        # æ ‡ç­¾å­—æ®µï¼ˆè¿™äº›å·²ç»æ˜¯è‹±æ–‡å­—æ®µåï¼‰
                        "basic_info_tags": doc.get("basic_info_tags", []),
                        "region_tags": doc.get("region_tags", []),
                        "energy_type_tags": doc.get("energy_type_tags", []),
                        "business_field_tags": doc.get("business_field_tags", []),
                        "beneficiary_tags": doc.get("beneficiary_tags", []),
                        "policy_measure_tags": doc.get("policy_measure_tags", []),
                        "importance_tags": doc.get("importance_tags", []),
                        
                        # æ—¶é—´å­—æ®µ
                        "created_at": doc.get("å¯¼å…¥æ—¶é—´") or doc.get("created_at", datetime.utcnow()),
                        "updated_at": doc.get("å¯¼å…¥æ—¶é—´") or doc.get("updated_at", datetime.utcnow()),
                        "view_count": doc.get("view_count", 0)
                    }
                    
                    # å¤„ç†å‘å¸ƒæ—¶é—´æ ¼å¼
                    if isinstance(mapped_doc["publish_time"], str):
                        try:
                            mapped_doc["publish_time"] = datetime.strptime(mapped_doc["publish_time"], "%Y-%m-%d")
                        except:
                            mapped_doc["publish_time"] = datetime.utcnow()
                    
                    # åˆ›å»ºContentå¯¹è±¡
                    content = Content(**mapped_doc)
                    articles.append(content)
                    
                except Exception as e:
                    logger.warning(f"è·³è¿‡æ— æ•ˆæ–‡æ¡£ {doc.get('_id')}: {str(e)}")
                    continue
            
            logger.info(f"âœ… æˆåŠŸå¤„ç† {len(articles)} ç¯‡æ–‡ç« ")
            
            return {
                "items": articles,
                "total": total_count,
                "page": page,
                "page_size": page_size,
                "has_next": (skip + len(articles)) < total_count
            }
            
        except Exception as e:
            logger.error(f"è·å–æ–‡ç« ç®¡ç†åˆ—è¡¨å¤±è´¥: {str(e)}")
            raise Exception(f"è·å–æ–‡ç« ç®¡ç†åˆ—è¡¨å¤±è´¥: {str(e)}")
    
    def _map_document_type(self, chinese_type: str) -> str:
        """å°†ä¸­æ–‡æ–‡æ¡£ç±»å‹æ˜ å°„ä¸ºè‹±æ–‡ç±»å‹"""
        type_mapping = {
            "æ”¿ç­–æ³•è§„": "policy",
            "è¡Œä¸šèµ„è®¯": "news", 
            "è°ƒä»·å…¬å‘Š": "price",
            "äº¤æ˜“å…¬å‘Š": "announcement"
        }
        return type_mapping.get(chinese_type, "news") 