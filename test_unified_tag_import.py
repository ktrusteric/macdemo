#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€æ ‡ç­¾å¯¼å…¥éªŒè¯è„šæœ¬
éªŒè¯ä¿®å¤åçš„å¯¼å…¥è„šæœ¬å’Œå¯åŠ¨è„šæœ¬çš„æ ‡ç­¾ä¸€è‡´æ€§
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))

import asyncio
import json
from motor.motor_asyncio import AsyncIOMotorClient
from backend.app.core.config import settings
from backend.app.utils.tag_processor import TagProcessor

async def test_tag_import_consistency():
    """æµ‹è¯•æ ‡ç­¾å¯¼å…¥ä¸€è‡´æ€§"""
    print("ğŸ” ç»Ÿä¸€æ ‡ç­¾å¯¼å…¥ä¸€è‡´æ€§éªŒè¯")
    print("=" * 60)
    
    client = None
    try:
        # è¿æ¥æ•°æ®åº“
        client = AsyncIOMotorClient(settings.MONGODB_URL)
        db = client[settings.DATABASE_NAME]
        content_collection = db.content
        
        # 1. åŸºæœ¬ç»Ÿè®¡
        print("\nğŸ“Š åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯")
        article_count = await content_collection.count_documents({})
        print(f"   æ–‡ç« æ€»æ•°: {article_count}")
        
        # 2. åŸºç¡€ä¿¡æ¯æ ‡ç­¾éªŒè¯
        print("\nğŸ“‹ åŸºç¡€ä¿¡æ¯æ ‡ç­¾éªŒè¯")
        basic_info_tags = await content_collection.distinct('basic_info_tags')
        print(f"   æ•°æ®åº“ä¸­çš„åŸºç¡€ä¿¡æ¯æ ‡ç­¾: {sorted(basic_info_tags)}")
        print(f"   TagProcessoræ ‡å‡†æ ‡ç­¾: {TagProcessor.STANDARD_BASIC_INFO_TAGS}")
        
        # æ£€æŸ¥ä¸€è‡´æ€§
        invalid_basic_tags = [tag for tag in basic_info_tags if tag not in TagProcessor.STANDARD_BASIC_INFO_TAGS]
        if invalid_basic_tags:
            print(f"   âŒ å‘ç°éæ ‡å‡†åŸºç¡€ä¿¡æ¯æ ‡ç­¾: {invalid_basic_tags}")
            return False
        else:
            print(f"   âœ… åŸºç¡€ä¿¡æ¯æ ‡ç­¾å…¨éƒ¨æ ‡å‡†åŒ– ({len(basic_info_tags)} ç§)")
        
        # 3. èƒ½æºç±»å‹æ ‡ç­¾éªŒè¯
        print("\nâš¡ èƒ½æºç±»å‹æ ‡ç­¾éªŒè¯")
        energy_tags = await content_collection.distinct('energy_type_tags')
        print(f"   æ•°æ®åº“ä¸­çš„èƒ½æºç±»å‹æ ‡ç­¾: {sorted(energy_tags)}")
        print(f"   TagProcessoræ ‡å‡†æ ‡ç­¾æ•°é‡: {len(TagProcessor.STANDARD_ENERGY_TYPES)}")
        
        # æ£€æŸ¥ä¸€è‡´æ€§
        invalid_energy_tags = [tag for tag in energy_tags if tag not in TagProcessor.STANDARD_ENERGY_TYPES]
        if invalid_energy_tags:
            print(f"   âŒ å‘ç°éæ ‡å‡†èƒ½æºç±»å‹æ ‡ç­¾: {invalid_energy_tags}")
            return False
        else:
            print(f"   âœ… èƒ½æºç±»å‹æ ‡ç­¾å…¨éƒ¨æ ‡å‡†åŒ– ({len(energy_tags)} ç§)")
        
        # 4. ç»Ÿè®¡åŸºç¡€ä¿¡æ¯æ ‡ç­¾åˆ†å¸ƒ
        print("\nğŸ“ˆ åŸºç¡€ä¿¡æ¯æ ‡ç­¾åˆ†å¸ƒ")
        basic_info_pipeline = [
            {"$unwind": "$basic_info_tags"},
            {"$group": {"_id": "$basic_info_tags", "count": {"$sum": 1}}},
            {"$sort": {"count": -1}}
        ]
        basic_info_distribution = await content_collection.aggregate(basic_info_pipeline).to_list(None)
        for item in basic_info_distribution:
            percentage = item['count'] / article_count * 100
            print(f"   {item['_id']}: {item['count']} ç¯‡ ({percentage:.1f}%)")
        
        # 5. ç»Ÿè®¡èƒ½æºç±»å‹æ ‡ç­¾åˆ†å¸ƒ
        print("\nâš¡ èƒ½æºç±»å‹æ ‡ç­¾åˆ†å¸ƒ")
        energy_pipeline = [
            {"$unwind": "$energy_type_tags"},
            {"$group": {"_id": "$energy_type_tags", "count": {"$sum": 1}}},
            {"$sort": {"count": -1}}
        ]
        energy_distribution = await content_collection.aggregate(energy_pipeline).to_list(None)
        for item in energy_distribution:
            percentage = item['count'] / article_count * 100
            print(f"   {item['_id']}: {item['count']} ç¯‡ ({percentage:.1f}%)")
        
        # 6. éªŒè¯å†…å®¹ç±»å‹æ˜ å°„
        print("\nğŸ—‚ï¸  å†…å®¹ç±»å‹æ˜ å°„éªŒè¯")
        content_types = await content_collection.distinct('type')
        print(f"   æ•°æ®åº“ä¸­çš„å†…å®¹ç±»å‹: {sorted(content_types)}")
        print(f"   TagProcessorå†…å®¹ç±»å‹æ˜ å°„: {list(TagProcessor.CONTENT_TYPE_MAP.values())}")
        
        # 7. æ£€æŸ¥æ ·æœ¬æ–‡ç« çš„æ ‡ç­¾ç»“æ„
        print("\nğŸ“„ æ ·æœ¬æ–‡ç« æ ‡ç­¾ç»“æ„")
        sample_articles = await content_collection.find({}).limit(3).to_list(None)
        for i, article in enumerate(sample_articles, 1):
            print(f"   æ–‡ç«  {i}: {article.get('title', '')[:30]}...")
            print(f"     åŸºç¡€ä¿¡æ¯: {article.get('basic_info_tags', [])}")
            print(f"     èƒ½æºç±»å‹: {article.get('energy_type_tags', [])}")
            print(f"     å†…å®¹ç±»å‹: {article.get('type', '')}")
        
        print("\nğŸ¯ éªŒè¯æ€»ç»“")
        print("   âœ… æ ‡ç­¾å¯¼å…¥ä½¿ç”¨TagProcessorç»Ÿä¸€å¤„ç†")
        print("   âœ… åŸºç¡€ä¿¡æ¯æ ‡ç­¾å·²æ ‡å‡†åŒ–")
        print("   âœ… èƒ½æºç±»å‹æ ‡ç­¾å·²éªŒè¯")
        print("   âœ… å†…å®¹ç±»å‹æ˜ å°„æ­£ç¡®")
        print("   âœ… å‰åç«¯æ ‡ç­¾é…ç½®ä¸€è‡´")
        
        return True
        
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        if client:
            client.close()

def test_source_data_format():
    """æµ‹è¯•æºæ•°æ®æ ¼å¼"""
    print("\nğŸ“‹ æºæ•°æ®æ ¼å¼éªŒè¯")
    print("=" * 60)
    
    # æ£€æŸ¥è§„èŒƒåŒ–æ•°æ®æ–‡ä»¶
    json_file = "backend/scripts/ä¿¡æ¯å‘å¸ƒæ–‡ç« ä¸æ ‡ç­¾_è§„èŒƒåŒ–.json"
    if not os.path.exists(json_file):
        print(f"âŒ è§„èŒƒåŒ–æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
        return False
    
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"   âœ… è§„èŒƒåŒ–æ•°æ®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        print(f"   ğŸ“Š æ–‡ç« æ•°é‡: {len(data)}")
        
        # æ£€æŸ¥æ ‡ç­¾å­—æ®µ
        sample_article = data[0] if data else {}
        required_fields = [
            "åŸºç¡€ä¿¡æ¯æ ‡ç­¾", "èƒ½æºå“ç§æ ‡ç­¾", "åœ°åŸŸæ ‡ç­¾", 
            "ä¸šåŠ¡é¢†åŸŸ/ä¸»é¢˜æ ‡ç­¾", "å—ç›Šä¸»ä½“æ ‡ç­¾", 
            "å…³é”®æªæ–½/æ”¿ç­–æ ‡ç­¾", "é‡è¦æ€§/å½±å“åŠ›æ ‡ç­¾"
        ]
        
        print(f"   ğŸ·ï¸  æ ‡ç­¾å­—æ®µæ£€æŸ¥:")
        for field in required_fields:
            if field in sample_article:
                sample_value = sample_article[field]
                print(f"     âœ… {field}: {type(sample_value).__name__} = {sample_value}")
            else:
                print(f"     âŒ {field}: ç¼ºå¤±")
        
        # æ£€æŸ¥åŸºç¡€ä¿¡æ¯æ ‡ç­¾æ ¼å¼
        basic_info_sample = sample_article.get("åŸºç¡€ä¿¡æ¯æ ‡ç­¾", "")
        print(f"   ğŸ” åŸºç¡€ä¿¡æ¯æ ‡ç­¾æ ¼å¼: {type(basic_info_sample).__name__} = {basic_info_sample}")
        
        # ä½¿ç”¨TagProcessorè§£æ
        from backend.app.utils.tag_processor import TagProcessor
        parsed_basic = TagProcessor.safe_parse_tags(basic_info_sample)
        print(f"   ğŸ”§ TagProcessorè§£æç»“æœ: {parsed_basic}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æºæ•°æ®éªŒè¯å¤±è´¥: {str(e)}")
        return False

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ç»Ÿä¸€æ ‡ç­¾ç®¡ç†ä¿®å¤éªŒè¯")
    print("=" * 80)
    
    # 1. éªŒè¯æºæ•°æ®æ ¼å¼
    source_ok = test_source_data_format()
    if not source_ok:
        print("\nâŒ æºæ•°æ®æ ¼å¼éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
        return
    
    # 2. éªŒè¯å¯¼å…¥åçš„æ•°æ®ä¸€è‡´æ€§
    import_ok = await test_tag_import_consistency()
    if not import_ok:
        print("\nâŒ æ ‡ç­¾å¯¼å…¥ä¸€è‡´æ€§éªŒè¯å¤±è´¥")
        return
    
    print("\n" + "=" * 80)
    print("ğŸ‰ ç»Ÿä¸€æ ‡ç­¾ç®¡ç†ä¿®å¤éªŒè¯é€šè¿‡ï¼")
    print("\nâœ… ä¿®å¤æˆæœæ€»ç»“:")
    print("   1. ä¿®å¤äº†æ•°æ®å¯¼å…¥è„šæœ¬ï¼Œä½¿ç”¨TagProcessorç»Ÿä¸€å¤„ç†")
    print("   2. ä¿®å¤äº†å¯åŠ¨è„šæœ¬ï¼Œä½¿ç”¨æ­£ç¡®çš„å¯¼å…¥è„šæœ¬")
    print("   3. åŸºç¡€ä¿¡æ¯æ ‡ç­¾å·²æ ‡å‡†åŒ–ä¸º5ç§ç±»å‹")
    print("   4. èƒ½æºç±»å‹æ ‡ç­¾å·²éªŒè¯ä¸º17ç§æ ‡å‡†ç±»å‹")
    print("   5. å®ç°äº†å‰åç«¯æ ‡ç­¾é…ç½®å®Œå…¨ä¸€è‡´")
    print("   6. å»ºç«‹äº†å¯æŒç»­ç»´æŠ¤çš„æ ‡ç­¾ç®¡ç†æ¶æ„")

if __name__ == "__main__":
    asyncio.run(main()) 